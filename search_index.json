[
["index.html", "edav.info/ Introduction 0.1 Everything you need for EDAV 0.2 How this resource is structured 0.3 Help improve edav.info/ 0.4 Fun stuff 0.5 Contact 0.6 License", " edav.info/ Zach Bogart, Joyce Robbins 2018-11-06 Introduction 0.1 Everything you need for EDAV This resource has everything you need and more to be successful with R, this EDAV course, and beyond. Let’s get started! With this resource, we try to give you a curated collection of tools and references that will make it easier to learn how to work with data in R. In addition, we include sections on basic chart types/tools so you can learn by doing. There are also several walkthroughs where we work with data and discuss problems as well as some tips/tricks that will help you. We hope this resource serves you well! This resource is specifically tailored to the GR5702 Exploratory Data Analysis and Visualization course offered at Columbia University. However, anyone interested in working with data in R will benefit from perusing these pages. 0.2 How this resource is structured This resource is split into four color-coded sections, each of which provides different kinds of assistance. Below is an explanation of each section: 0.2.1 Section I: Information (Blue) Pages in the blue section contain basic information. Examples of blue pages include this introduction page and the basics page, which explains how to setup R/RStudio as well as ways to get help if you need it. Blue pages are the help desk of this resource: look to them if you are lost and need to find your way. 0.2.2 Section II: Walkthroughs (Red) Pages in the red section contain more extensive walkthroughs. An example of a red page is the iris walkthrough, where a well-known dataset is presented as a pretty scatterplot and steps are shown from start to finish. This page type is the most thorough: it tries to provide full documentation, explanations of design choices, and advice on best practices. It’s like going to office hours and having a great clarifying chat with a course assistant…in article form. If you would like to see a fully-worked-through example of something with a lot of guidance along the way, check out the red pages. 0.2.3 Section III: Documentation (Green) Pages in the green section contain more compact documentation. An example of a green page is the histogram page, which includes simple examples of how to create histograms, when to use them, and things to be aware of/watch out for. The green pages hold your hand much less than the red pages: they explain how to use a chart/tool using examples and simple terms. If you have an idea in mind and are just wondering how to execute it, the green pages will help fill in those gaps. 0.2.4 Section IV: References (Yellow) Pages in the yellow section contain simple collections of references. An example of a yellow page is the external resources page, which is a list of materials that you can look through and learn from. Yellow pages have the least amount of hand-holding: they are collections of resources and bare-boned tutorials that will help you learn about new things. 0.3 Help improve edav.info/ This resource is an ongoing creation made by students, for students. We welcome you to help make it better. Not finding what you are looking for? Think a section could be made clearer? Consider helping improve edav.info/ by submitting a pull request to the github page. Don’t understand that last sentence? We have a page on how you can contribute to edav.info/. 0.4 Fun stuff 0.4.1 T-shirts Zach Bogart has made a few t-shirts available on Teespring so you can show your love for EDAV and R. Hope you enjoy! P.S. Designing a cool shirt or sticker is a great addition to your community contribution. It has to be cool, though 0.5 Contact Zach Bogart: Website / Twitter / GitHub Joyce Robbins: Columbia Profile / Website / Twitter / GitHub 0.6 License This work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License. "],
["basics.html", "1 R Basics 1.1 Essentials checklist 1.2 Getting started 1.3 Packages and imports 1.4 Communicating Results 1.5 Getting help", " 1 R Basics So…there is soooo much to the world of R. Textbooks, cheatsheets, exercises, and other buzzwords full of resources you could go through. There are over 13300 packages on CRAN, the network through which R code and packages are distributed. It can be overwhelming. However, bear in mind that R is being used for a lot of different things, not all of which are relevant to EDAV. To help you navigate the landscape, here we provide a collection of resources that you should be familiar with in the context of this course. This is not to say that any of these resources are prerequisites, but they will come up in the course and we want to give you places to learn about them. Since people come with a variety of backgrounds, we will try to provide the essentials as well as some resources for more advanced users. Do not feel you have to go through all of these resources, but know that they are here if/when you need them. 1.1 Essentials checklist In an effort to get everyone on the same page, here is a checklist of essentials so you can get up and running with this course. It will echo/reference a lot of info said below, but we want to make sure everything mentioned is clear and understood. Okay, then. Here are the essentials, in checklist form: 1.1.1 Learn R Download R and RStudio: This is the biggest thing to do by far. Make sure to download both R and RStudio, as mentioned in Setting up R and RStudio. Learn your way around RStudio: RStudio is powerful…if you know how to use it. Take the time to look through the DataCamp sections on the RStudio IDE so you feel comfortable (see Use RStudio like a pro section). Try something!: Getting comfortable with an IDE is all about practice. So while the DataCamp vids are great, don’t solely rely on them. Try things out for yourself! Here are some things to play around with: Create an R Script file, paste in print(&quot;Hello, World!&quot;), and run it Create an R Markdown file and have it generate an HTML page Download some packages like tidyverse or MASS Do some math in the console Study R: See Learning about R below. Learn how to get help: Make sure you are comfortable searching for answers when you get stuck. See the section below on getting help for some…help. 1.1.2 Prepare for class Get the Textbook: This course uses Graphical Data Analysis with R as its textbook. Here is an Amazon link for a physical copy and a link to the book’s website. Setup DataCamp Account: A lot of the references and support materials discussed in edav.info/ are from DataCamp, an online collection of courses/articles on data science. Some of the sections are free, but most are behind a paywall. However, DataCamp currently provides full access to the site for students with .edu email addresses. If you are enrolled in this course, during the first week of class you will receive an invitation to create an account using your columbia.edu email address, which will grant you full access. 1.2 Getting started 1.2.1 Setting up R and RStudio It is super important to get up and running with R and RStudio as soon as you can. This video from DataCamp pretty much covers it. Know that you will be downloading two separate things: R, which is a programming language; and RStudio, which is an IDE (integrated development environment…fancy tool for working with R) that will make working with R a lot more enjoyable. 1.2.2 Use RStudio like a pro Great! RStudio is up and running on your computer! Now make sure you get comfy with what it can do. Don’t know your way around the RStudio IDE? I highly recommend this DataCamp course. Sections from Part 1 (Orientation, Programming, and Projects) are the most relevant for this course. They include videos about all the regions in RStudio, how to program efficiently/effectively in the IDE (gotta love those keyboard shortcuts), and the benefits of setting up R projects. A little hazy on that last sentence? The course will help. Just want a quick reference to brush up with? Take a look at the RStudio Cheatsheets page. Another option is this RStudio webinar. Want to make the RStudio IDE your own? Look into modifying the preferences. You can customize the look of the IDE like default colors and typefaces, tweak default behaviors like clearing the environment on load, and integrate a session with a git repository. If something about the IDE bugs you, chances are you can make it more to your liking. 1.2.3 Learning about R R is just like any language, programming or otherwise: you need to use it to get used to it. Just starting out in R? Check out this free DataCamp course for a quick introduction. For this course, you can skim/mostly ignore matrices and lists (Parts 3 &amp; 6). Next cover the material in the first section of R for Data Science It is based on the tidyverse, a group of packages which, among other things, make it easier to code in R: Data Visualization Workflow: basics Data transformation Workflow: scripts Exploratory Data Analysis Workflow: projects General advice: don’t get caught up in the details. Keep a list of questions and move on. 1.3 Packages and imports 1.3.1 Installing packages A lot of the cool stuff comes from installing packages into R. How do you install packages? The main function we use is install.packages(&quot;&lt;package_name&gt;&quot;), which installs from CRAN, a well-known place where packages are stored. Then, once installed, you can use packages by calling them within library(). Still confused? This DataCamp video should help explain the process. Also be sure to try the accompanying exercise to make sure you have a feel for loading a package. Want more info? Check out this DataCamp article on everything about installing packages in R. As well as covering the basics, this article shows you how to install packages that are not located on CRAN using devtools, as well as ways to monitor the status/health of your installed packages. 1.3.2 Tidyverse Don’t know what the tidyverse is? It’s great and we use it throughout this course. Specifically, ggplot2 and dplyr, two packages within the Tidyverse. What’s ggplot? Check out this DataCamp course. This course is split up into three parts and it is quite long, but it does go over pretty much everything ggplot has to offer. If you are starting out, stick with Part 1. What’s dplyr? Make friends with this DataCamp course. It goes through the main dplyr verbs: select, mutate, filter, arrange, summarise; as well as the lovely pipe operator. Want case studies to go through? Try this one or this one. 1.3.3 Importing data We often will need to pull data into RStudio to work with it. “Pull data”? I’m already confused. But wait! Here’s a DataCamp course on importing data using dplyr. Note: This course explains how to import every kind of data format under the sun…all you need to be familiar with for this course (mostly) is pulling in CSV files using read_csv. So, if you are overwhelmed, just stick to the read_csv stuff. Importing every data format under the sun you say? I want to know how to do that. Here’s Part 1, as well as Part 2, which focuses on databases and HTTP requests. Go nuts. 1.4 Communicating Results 1.4.1 R Markdown &amp; Knitr R Markdown is how you will be writing assignments for this course and Knitr is how you will generate an output file for submission. In general, they’re a great way to communicate your findings to others (for the python-lovers among you, this is the Jupyter Notebook of the R world). Want to jump right in? Open a new R Markdown file (File &gt; New File &gt; R Markdown…), and set its Default Output Format to HTML. You will get a R Markdown template you can tinker with. Try knitting the document to see what everything does. For more info on what is happening behind the scenes, checkout this R Markdown Quick Tour. Want a simple description of R Markdown? Checkout this RStudio article for a description on how to combine text, source code, and output into one document. Prefer videos? DataCamp course to the rescue! There is also an RStudio webinar about it. Don’t know about Knitr? Here’s the specific section on Knitr from the DataCamp course cited above. With this package, you can embed code directly into your R Markdown files and generate output documents. Make sure to go through the later exercises to learn about code chunks and chunk options so you can fine-tune your final output document with ease. Wondering what chunk options are? Have you ever wanted to align graphs in your output PDF differently? Or re-size a plot in your output document? Or suppress an annoying message a package raises? Chunk options address this. We have made an R Markdown file showing off different chunk options that you can download from our github repo and play around with. Also make sure to checkout the documentation on chunk and package options for a full list of what’s possible. The R Markdown page from RStudio has lessons with extensive info. Also, more cheatsheets. 1.4.2 Submitting Assignments Here’s a quick run-down of how to submit your assignments using R Markdown and Knitr. Create R Markdown file with PDF output format: We will often provide you with a template, and feel free to add on to it directly, but make sure its output format is set to pdf_document. Write out your explanations and insert code chunks to answer the questions provided. If you want to make a new file, go to File &gt; New File &gt; R Markdown… and set the Default Output Format to PDF. Either way, the header of the .Rmd file should look something like this: Add PDF Dependencies: As stated when you create a new R Markdown file, the PDF output format requires TeX: Make sure you download TeX for your machine. Here are some Medium articles on the process of creating PDF reports (the articles cover starting from scratch with no installs at all, but you can skip over to installing TeX only): Mac OS Windows This can be a little complicated, but it will make that Knit button near the top of the IDE magically generate a PDF for you. If you are in a rush and want a shortcut, you can instead set the Default Output Format to HTML. When you open the file in your browser, you can save it as a PDF. It will not be as nicely formatted, but it will still work. 1.5 Getting help via https://dev.to/rly First off…breeeeeeathe. We can fix this. There are a bunch of resources out there that can help you. 1.5.1 Things to try Remember: Always try to help yourself! This article has a great list of tools to help you learn about anything you may be confused by. This includes learning about functions and packages as well as searching for info about a function/package/problem/etc. This is the perfect place to learn how to get the info you need. The RStudio Help menu (in the top toolbar) is a fantastic place to go for understanding/fixing any problems. There are links to documentation and manuals as well as cheatsheets and a lovely collection of keyboard shortcuts. Vignettes are a great way to learn about packages and how they work. Vignettes are like stylized manuals that can do a better job at explaining a package’s contents. For example, ggplot2 has a vignette on aesthetics called ggplot2-specs that talks about different ways you can map data to different formats. Typing browseVignettes() in the console will show you all the vignettes for all of the packages you have installed. You can also see vignettes by package by typing vignette(package = &quot;&lt;package_name&gt;&quot;) into the console. To run a specific vignette, use vignette(&quot;&lt;vignette_name&gt;&quot;). If the vignette can’t be resolved, include the package name as well: vignette(&quot;&lt;vignette_name&quot;, package = &quot;&lt;package_name&gt;&quot;) Don’t ignore errors. They are telling you so much! If you give up because red text showed up in your console, take the time to see what that red text is saying. Learn how to read errors and what they are telling you. They usually include where the problem happened and what R thinks the problem stems from. More Advanced: Learn to love debugger mode. Debugging can have a steep learning curve, but huge payoffs. Take a look at these videos about debugging with R. Topics include running the debugger, setting breakpoints, customizing preferences, and more. Note: R Markdown files have some limitations for debugging, as discussed in this article. You could also consider working out your code in a .R file before including it in your R Markdown homework submission. 1.5.2 Help me, R community! Relax. There are a bunch of people using the same tools you are. Your fellow classmates are a good place to start! Post questions to Piazza to see how they could help. There is a lot of great documentation on R and its functions/packages/etc. Get comfy with R Documentation and it will help you immensely. There is a vibrant RStudio Community page. Also, R likes twitter. Check out #rstats or maybe let Hadley Wickham know about a wonky error message. "],
["project.html", "2 Final Project Assignment 2.1 Overview 2.2 General info 2.3 Outline 2.4 FAQ 2.5 Executive summary notes 2.6 Resources", " 2 Final Project Assignment 2.1 Overview This section goes over what’s expected for the final project. General Note: Please note that this sheet cannot possibly cover all the “do’s and don’ts” of data analysis and visualization. You are expected to follow all of the best practices discussed in class throughout the semester. 2.2 General info 2.2.1 Goal The goal of this project is to perform an exploratory data analysis / create visualizations with data of your choosing in order to gain preliminary insights on questions of interest to you. 2.2.2 Teams You must work in teams of 2-4 people. (If you have specific interests you should try to find partners on Piazza first as we will not be able to match on specific criteria – we will simply assign groups in the order in which responses come in.) 2.2.3 Signup Please create a group by clicking on the People tab in CourseWorks, and then Student Groups. Next add the members of your group by dragging the names into the group. Please use the following naming convention for your group name: Columbia UNIs in alphabetical order, with underscores separating names, for example: jtr13_rar3010_sw2934. Remember that final project groups may have between 2 and 4 members. Once you do so, we will create a copy of your group as a Final Project Group, which appears as a separate tab in the People section of CourseWorks. (If you’re wondering, this is necessary since Student Groups cannot be used for graded assignments due to the way CourseWorks is designed.) If you don’t sign up by the November 1 deadline, you will be assigned to a group randomly on November 2. That is not a bad option, and more realistic in terms of preparing yourself for a work environment. Once the groups are set up, we will ask for a short description of your project ideas, so start planning! 2.2.4 Topics The topic you choose is open-ended… choose something that you are intereted in and genuinely curious about! Think of some questions that you don’t know the answer to. Next look for data that might help you answer those questions. 2.2.5 Data The data can be pulled from multiple sources; it does not need to be a single dataset. Be sure to get data from the original source. For example, if you wish to work with data collected and distributed by the Centers for Disease Control, that is where you should go to access the data, not a third party that has posted the data. Avoid overused datasets (think Titanic) as well as those used in Kaggle (or similar) competitions. A few examples are: NYC Open Data US Bureau of Labor Statistics 2.2.6 Code All of your code should be stored on GitHub. In your report, include a link to the repo, as well as links to specific files as relevant. The static visualizations should be done in R, but other pieces, such as data importation and cleaning do not. 2.2.7 Analysis You have a lot of freedom to choose what to do, as long as you restrict yourselves to exploratory techniques (rather than modeling / prediction approaches). In addition, your analysis must be clearly documented and reproducible. 2.2.8 Feedback At any point, you may ask the TAs (Bridget and Zach) or the instructor (Joyce) for advice. Our primary role in this regard will be to provide general guidance on your choice of data / topic / direction. As always, you are encouraged to post specific questions to Piazza, particularly coding questions and issues. You may also volunteer to discuss your project with the class in order to get feedback–if you’d like to do this, email the instructor to schedule a date. 2.2.9 Peer review A portion of your grade is based on the feedback you give to other groups. After the due date, each individual will be assigned two project groups to review, and instructions will be provided. Note: part of the grade you receive for the class is based on the quality of review that you write, not on the feedback that your project receives. Your grade for the project (as for all other assignments for the class) will be determined solely by the instructor and TAs. 2.2.10 Report format With the exception of the interactive part, your project should be submitted to CourseWorks as an .Rmd and .html or pdf file, with graphs / output rendered. If it’s not feasible to include certain portions of your material in the report, make those parts available online (for example, GitHub), and provide links to them in the report. You will lose points if we have trouble reading your file, need to ask you to resubmit with graphs visible, if links are broken, or if we have other difficulties accessing your materials. It’s ok if code is in different files and different places, just make sure there are working links in your report to these locations. Note: Using Markdown + code chunks is supposed to make combining code, text and graphs easier. If it is making it more difficult, you are probably trying to do something that isn’t well suited to the tool set. Focus on the text and graphs, not the formatting. If you’re not sure if something is important to focus on or not, please ask. Advice: don’t wait to start writing. Your overall project will undoubtedly be better if you give up trying to get that last graph perfect or the last bit of analysis done and get to the writing! 2.2.11 A note on style You are encouraged to be as intellectually honest as possible. That means pointing out flaws in your work, detailing obstacles, disagreements, decision points, etc. – the kinds of “behind-the-scene” things that are important but often left out of reports. You may use the first person (“I”/“We”) or specific team members’ names, as relevant. 2.3 Outline Your report should include the following sections, with subtitles (“Introduction”, etc.) as indicated: 2.3.1 Introduction Explain why you chose this topic, and the questions you are interested in studying. List team members and a description of how each contributed to the project. 2.3.2 Description of data Describe how the data was collected, how you accessed it, and any other noteworthy features. 2.3.3 Analysis of data quality Provide a detailed, well-organized description of data quality, including textual description, graphs, and code. 2.3.4 Main analysis (Exploratory Data Analysis) Provide a detailed, well-organized description of your findings, including textual description, graphs, and code. Your focus should be on both the results and the process. Include, as reasonable and relevant, approaches that didn’t work, challenges, the data cleaning process, etc. 2.3.5 Executive summary (Presentation-style) Provide a short nontechnical summary of the most revealing findings of your analysis written for a nontechnical audience. The length should be approximately two pages (if we were using pages…) Take extra care to clean up your graphs, ensuring that best practices for presentation are followed. Note: “Presentation” here refers to the style of graph, that is, graphs that are cleaned up for presentation, as opposed to the rough ones we often use for exploratory data analysis. You do not have to present your work to the class! However, you may choose to present your work as your community contribution, in which case you need to email me to set a date before the community contribution due date. (The presentation itself may be later.) 2.3.6 Interactive component Select one (or more) of your key findings to present in an interactive format. Be selective in the choices that you present to the user; the idea is that in 5-10 minutes, users should have a good sense of the question(s) that you are interested in and the trends you’ve identified in the data. In other words, they should understand the value of the analysis, be it business value, scientific value, general knowledge, etc. Interactive graphs must follow all of the best practices as with static graphs in terms of perception, labeling, accuracy, etc. You may choose the tool (D3, Shiny, or other) The complexity of your tool will be taken into account: we expect more complexity from a higher-level tool like Shiny than a lower-level tool like D3, which requires you to build a lot from scratch. Make sure that the user is clear on what the tool does and how to use it. Publish your graph somewhere on the web and provide a link in your report in the interactive section. The obvious choices are blockbuilder.org to create a block for D3, and shinyapps.io for Shiny apps but other options are fine. You are encouraged to share experiences on Piazza to help classmates with the publishing process. As applicable, all of the following will be considered in the grading process: Choice of data and plot types to present Clear relevance to question(s), project in general Design of interactive component(s) Clarity of presentation, including instructions Technical execution (include a description of what you would work on in the future, what you’ve attempted, etc. so we know it’s on your radar) 2.3.7 Conclusion Discuss limitations and future directions, lessons learned. 2.4 FAQ How long should the project be? It should take the reader approximately 15-20 minutes to read the report. We cannot provide a specific number of graphs or pages since there are so many variables. Use your judgment to cover all of the important material without being repetitive. You can report on what you’ve done without including all of the graphs; for example, if you looked at maps of each of the fifty states you can include 1 or 2 as examples. Do we have to present the project to the class? No. Presenting your project as your community contribution is optional. Someone has already used the same data, is that ok? Yes. As long as you get the data from the original source, not a site like Kaggle, you’re fine. You can check with the professor if you want to be sure. I spent 30 minutes looking at my data, and then 1000 hours building this super cool interactive app so users can analyze the data themselves. Can’t you count the interactive part for 95% of my grade? No. While skill sets overlap in the real world, and it’s important to know something about building things, the assumption is that you are doing the work of the data scientist: actually analyzing the data rather than building tools for someone else to do it. The former (the data!) has been the main focus of this class and therefore is the primary focus of the final project. 2.5 Executive summary notes The executive summary should be a well-formatted, presentable final product of your results. Here are some notes to consider when putting it together: Title, axis labels, tick mark labels, and legends should be comprehensible (easy to understand) and legible (easy to read / decipher). Tick marks should not be labeled in scientific notation or with long strings of zeros, such as 3000000000. Instead, convert to smaller numbers and change the units: 3000000000 becomes “3” and the axis label “billions of views”. Units should be intuitive (An axis labeled in month/day/year format is intuitive; one labeled in seconds since January 1, 1970 is not.) The font size should be large enough to read clearly. The default in ggplot2 is generally too small. You can easily change it by passing the base font size to the theme, such as + theme_grey(16) (The default base font size is 11). The order of items on the axes and legends should be logical. (Alphabetical is usually not the best option.) Colors should be color-vision-deficiency-friendly. If categorical variable levels are long, set up the graph so the categorical variable is on the y-axis and the names are horizontal. A better option, if possible, is to shorten the names of the levels. Not all EDA graphs lend themselves to presentation, either because the graph form is hard to understand without practice or it’s not well labeled. The labeling problem can be solved by adding text in an image editor. The downside is that it is not reproducible. If you want to go this route, for the Mac, Keynote and Paintbrush are good, free options. Err on the side of simplicity. Don’t, for example, overuse color when it’s not necessary. Ask yourself: does color make this graph any clearer? If it doesn’t, leave it out. Test your graphs on nontechnical friends and family and ask for feedback. Above all, have fun with it 2.6 Resources “Tidy Tuesday Screencast: analyzing college major &amp; income data in R” David Robinson explores a dataset in R live, without looking at the data in advance. "],
["contribute.html", "3 Contribute to this Resource 3.1 Overview 3.2 Why contribute? 3.3 Ways you can contribute 3.4 Resources", " 3 Contribute to this Resource 3.1 Overview This page explains how to contribute to edav.info/. 3.2 Why contribute? We don’t want edav.info/ to be just another resource. Rather, we want it to be your resource. If there are things that trip you up or cause you frustration, chances are you’re not alone. Everyone comes to this course with different backgrounds and expertise. Being able to collect all that knowledge in one place is this resource’s mission and you can help move that mission forward. 3.3 Ways you can contribute There are three main ways you can contribute: For simple changes contribute directly (we got a full walkthrough on how to do this) For bigger/more abstract suggestions submit an issue (very simple, much appreciated) For adventurous/social GitHub users solve an open issue (more advanced/open-ended, also much appreciated) Below you’ll find more detail on each option. Happy coding! 3.3.1 Contribute directly One way to contribute to edav.info/ is to contribute directly by editing a chapter. At the top of every page of this resource, you will see an icon that looks like this: . Clicking it will open a new tab where you can edit the markdown for that page on our GitHub repo and submit your change as a pull request. Essentially, you will create a copy of our repo, make your desired changes, and suggest to us that we include them. If we approve of your changes, they will be rendered and published to the site. Contributing directly works best if the change you are proposing is something relatively small, such as: A typo/grammatical error An unclear phrasing/explanation A quick code fix 3.3.1.1 Direct contribution walkthrough This is a full walkthough on proposing a change to edav.info/. It follows a hypothetical student that spots a typo and uses a pull request to fix it. It’s a little long, but don’t get scared; it’s a great way to learn about GitHub and it’s almost entirely hitting big green buttons! Let’s find something to change. I’m pretty sure they meant to write “repository” here. Oops. Let’s fix it for them! That’s not how you spell “repository”! Let’s fix it. To make the fix, we click on the edit icon, , at the top of the page. This will take us to their GitHub repo, where all the code for this resource is stored. Note: You need to have a valid GitHub account to contribute. In this example, we are using a dummy account called excited-student so if you see it in a screenshot, know that it would be replaced by your own username. Hit this icon to go to GitHub. We haven’t forked the repo yet, so GitHub shows us a page like the one below. No worries! We just hit the big green button labeled Fork this repository and propose changes and we’ll be good to go (as you will see, big green buttons are our friends). For more info on forking repos, the GitHub Guide on Forking Projects is very informative. Note: you will not have to fork the repo every time. If you propose another change in the future, the edit icon, , will jump you directly to this point of the walkthrough. Just remember to keep your fork up to date. Haven’t forked the repo before? No worries; the big green button will solve everything. Now that we have successfully forked the repo, we can see the code for the page we want to edit. Note: That little blue blurb at the top is spelling out what is happening/going to happen: we have made a copy of a repo because we don’t have write access to it . So, after we make our change on this page, we will inform the owners of the repo about our edits by using a pull request. GitHub can be super overwhelming, but it will try its darndest to inform you what will happen along the way. Ready to edit the code. The blue blurb is worth reading. Let’s fix that embarrassing typo! We update the code right in this editor, include an explanation for what we changed/why we made the change, and then hit the big green button labeled Propose file change. Gotta love those big green buttons! Make your edits, include a quick explanation, and hit the big green button. Now GitHub is once again helping out by letting us review the changes we made. On this page we can review our proposed changes by scrolling down and looking at the diffs. Our fix is very simple so there isn’t much to see. Once again, we are going to push the big green button, this time labeled Create pull request. This will start the process of letting the edav.info/ people know that we would like them to include our changes (in git-speak, we are requesting that the edav.info/ people do a git merge to update their files with our proposed changes.) Chance to review your changes. Once satisfied, hit the big green button to start a pull request. Here we are at the pull request page. Notice the green checkmark that says “Able to merge” (a good sign that everything is going smoothly). Now we explain our pull request with some comments and, once again, hit the big green button labeled Create pull request. Note: You may be asking, “Why do I have to type this explanation in again?”. This is because the explanation we wrote in Step 5 (where we edited the file) is a commit. We could have had multiple commits at once that we wanted to bundle into one pull request. This step is a way to explain the pull request as a whole. It is redundant for us because our change is so small and only has one commit. Still totally lost? This GitHub Guide on Understanding the GitHub Flow is an incredibly helpful read and our GitHub Resources page also has a lot of helpful links. Explain your pull request and hit the big green button. Congratulations are in order! We have successfully opened a pull request on a GitHub repo! Now one of the repo owners (like the guy writing this tutorial, for example ) has to decide if they want to include your pull request or not. In this case they’ll certainly approve it, but know that they may decide against adding your changes. For more info, read the section of the Open Source Guides on what happens after you submit a contribution. Note: Be aware that the icon shown below may initially be yellow to signal that some tests are being performed to check the conflicts of your proposal with the original repo. It should turn green if everything passes. We did it! Now the maintainers will review our changes and get back to us… And now we wait… via GIPHY What’s this!? We have received an email from one of the repo owners, Zach Bogart. And it says that they merged the change! Huzzah! We click on the number to take us back to the pull request we opened. We got an email! And it says they merged! Click that number to see the updated pull request. Here we are at the updated pull request page. Notice that everything has turned purple. Purple is the best color to see on GitHub; it’s the color of victory. It signals that our pull request was merged with the repo, meaning our change has become part of the repo! Also, notice the button that says Delete branch. Since all the work on our branch was merged with the repo, it has served its purpose and can be deleted safely. Everything is purple! Woot! Can safely delete our branch Now if we go back to the main page of the repo, we can see our merge was the most recent addition. And, if we scroll down, we will see that github_resources.Rmd, the file we edited, has been updated recently and it shows our commit message “fix typo”. We did it! Let’s check out the site to see our change published for the whole internet to see! Look! There’s our merged pull request added to the repo! And the edits we made to github_resources.Rmd! There it is! We go back to the page we edited and now our typo fix has been included!Note: The changes will take several minutes to appear on the site after notification of a successful merge. This is because we use Travis CI on the backend of our repo and it takes a little time for it to re-render the site pages. If you want to learn more about how you can use Travis CI to auto-magically generate your work, checkout our section on Hooking Up Travis to a GitHub bookdown book in the Publishing Resources page. Look at that! It’s published! So many exclamation points!!! We contributed to a GitHub repo! Hooray! Time to celebrate! via GIPHY If what you want to improve is a little more substantial (too difficult to contribute directly), read on. 3.3.2 Submit an issue If your proposed change is more complex, consider letting us know by submitting an issue. Maybe you have a great idea for a brand new chapter, something we have not covered but would like to see here in this resource (a new chart page, say; or a walkthrough using a specific tool/package). It may be a little too complicated to contribute directly. What to do? Submit an issue, of course! Issues are tasks you can post to a GitHub repo that people can then take on and fix. They can be small (“this link is broken” / “add this resource”) or complex (“I would love to have a chapter on…” / “reformat this code chunk in this way”). Once posted, issues can be taken on by anyone. You do not have to know how to code up your issue; from fixing a bug to proposing a resource we should link to, we appreciate any feedback you have and will take it all into consideration. How to submit issues: Go to our GitHub repo and click on the Issues Tab Click on “New Issue” Propose your Issue and click “Submit new issue” That’s it! We appreciate your input and will take your issue into account in improving edav.info/ Notes about submitting issues: Make sure your changes are not already an open issue (so as not to have redundant issues) Please thoroughly explain your proposed change when posting a new issue Consider using labels to specify the kind of issue, such as “bug”, “enhancement”, “help wanted”, “question”, or create your own. For more info, please consider reading the Open Source Guide on how to contribute. 3.3.3 Solve an open issue If you see an open issue that you think you can solve, by all means go for it! Simply fork our repo, add to the code base, and submit your work as a pull request. Checkout our open issues to see what needs doing. We appreciate any input you may have. Note: before getting too far into changing something, let us know in the github issue that you are working on solving it. This makes sure we are all on the same page. Confused how to actually do what was mentioned above? We have a thorough walkthrough example that should help and make sure to checkout our GitHub references page for links to learn about GitHub. For more info, please consider reading the GitHub Guide on Forking Projects and the Open Source Guide on how to contribute. 3.4 Resources Our GitHub repo: Link to the GitHub repository for edav.info/ Open Source Guide: Fantastic guide on how to contribute to projects like this one Our Page of GitHub Resources: Confused about the GitHub basics? Checkout our page of resources (once you learn more about git, you’ll realize that was a joke). "],
["iris.html", "4 Walkthrough: Iris Example 4.1 Overview 4.2 Quick note on doing it the lazy way 4.3 Viewing data 4.4 Plotting data 4.5 Markdown etiquette 4.6 Overlapping data 4.7 Formatting for presentation 4.8 Alter appearance 4.9 Consider themes 4.10 Going deeper 4.11 Helpful links", " 4 Walkthrough: Iris Example 4.1 Overview This example goes through some work with the iris dataset to get to a finished scatterplot that is ready to present. 4.1.1 tl;dr Here’s what we end up with: library(ggplot2) base_plot &lt;- ggplot(data = iris, mapping = aes(x = Sepal.Length, y = Sepal.Width)) + geom_point(aes(color = Species), size = 3, alpha = 0.5, position = &quot;jitter&quot;) + xlab(&quot;Sepal Length (cm)&quot;) + ylab(&quot;Sepal Width (cm)&quot;) + ggtitle(&quot;Sepal Dimensions in Different Species of Iris Flowers&quot;) base_plot + theme_minimal() Wondering how we got there? Read on. 4.1.2 Packages ggplot2 dplyr stats Base datasets (gridExtra) 4.1.3 Techniques Keyboard Shortcuts Viewing Data Structure/Dimensions/etc. Accessing Documentation Plotting with ggplot2 Layered Nature of ggplot2/Grammar of Graphics Mapping aesthetics in ggplot2 Overlapping Data: alpha and jitter Presenting Graphics Themes 4.2 Quick note on doing it the lazy way Shortcuts are your best friend to get work done faster. And they are easy to find. In the toolbar: Tools &gt; Keyboard Shortcuts Help OR ⌥⇧K Some good ones: Insert assignment operator (&lt;-): Alt/Option+- Insert pipe (%&gt;%): Ctrl/Cmd+Shift+M Comment Code: Ctrl/Cmd+Shift+C Run current line/selection: Ctrl/Cmd+Enter Re-run previous region: Ctrl/Cmd+Shift+P Be on the lookout for things you do often and try to see if there is a faster way to do them. Additionally, the RStudio IDE can be a little daunting, but it is full of useful tools that you can read about in this cheatsheet or go through with this DataCamp course: Part 1, Part 2. Okay, now let’s get to it… 4.3 Viewing data Let’s start with loading the package so we can get the data as a dataframe. library(datasets) class(iris) ## [1] &quot;data.frame&quot; This is not a huge dataset, but it is helpful to get into the habit of treating datasets as large no matter what. Because of this, make sure you inspect the size and structure of your dataset before going and printing it to the console. Here we can see that we have 150 observations across 5 different variables. dim(iris) ## [1] 150 5 There are a bunch of ways to get information on your dataset. Here are a few: str(iris) ## &#39;data.frame&#39;: 150 obs. of 5 variables: ## $ Sepal.Length: num 5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ... ## $ Sepal.Width : num 3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ... ## $ Petal.Length: num 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ... ## $ Petal.Width : num 0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ... ## $ Species : Factor w/ 3 levels &quot;setosa&quot;,&quot;versicolor&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... summary(iris) ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## Min. :4.300 Min. :2.000 Min. :1.000 Min. :0.100 ## 1st Qu.:5.100 1st Qu.:2.800 1st Qu.:1.600 1st Qu.:0.300 ## Median :5.800 Median :3.000 Median :4.350 Median :1.300 ## Mean :5.843 Mean :3.057 Mean :3.758 Mean :1.199 ## 3rd Qu.:6.400 3rd Qu.:3.300 3rd Qu.:5.100 3rd Qu.:1.800 ## Max. :7.900 Max. :4.400 Max. :6.900 Max. :2.500 ## Species ## setosa :50 ## versicolor:50 ## virginica :50 ## ## ## # This one requires dplyr, but it&#39;s worth it :) library(dplyr) glimpse(iris) ## Observations: 150 ## Variables: 5 ## $ Sepal.Length &lt;dbl&gt; 5.1, 4.9, 4.7, 4.6, 5.0, 5.4, 4.6, 5.0, 4.4, 4.9,... ## $ Sepal.Width &lt;dbl&gt; 3.5, 3.0, 3.2, 3.1, 3.6, 3.9, 3.4, 3.4, 2.9, 3.1,... ## $ Petal.Length &lt;dbl&gt; 1.4, 1.4, 1.3, 1.5, 1.4, 1.7, 1.4, 1.5, 1.4, 1.5,... ## $ Petal.Width &lt;dbl&gt; 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.3, 0.2, 0.2, 0.1,... ## $ Species &lt;fct&gt; setosa, setosa, setosa, setosa, setosa, setosa, s... Plotting the data by calling iris to the console will print the whole thing. Go ahead and try it in this case, but this is not recommended for larger datasets. Instead, use head() in the console or View(). If you want to learn more about these commands, or anything for that matter, just type ?&lt;command&gt; into the console. ?head, for example, will reveal that there is an additional argument to head called n for the number of lines printed, which defaults to 6. Also, you may notice there is something called tail. I wonder what that does? 4.4 Plotting data Let’s plot something! # Something&#39;s missing library(ggplot2) ggplot(iris) Where is it? Maybe if we add some aesthetics. I remember that was an important word that came up somewhere: # Still not working... ggplot(data = iris, mapping = aes(x = Sepal.Length, y = Sepal.Width)) Still nothing. Remember, you have to add a geom for something to show up. # There we go! ggplot(data = iris, mapping = aes(x = Sepal.Length, y = Sepal.Width)) + geom_point() Yay! Something showed up! Notice where we put the data, inside of ggplot(). ggplot is built on layers. Here we put it in the main call to ggplot. The data argument is also available in geom_point(), but in that case it would only apply to that layer. Here, we are saying, for all layers, unless specified, make the data be iris. Now let’s add a color mapping by Species: ggplot(data = iris, mapping = aes(x = Sepal.Length, y = Sepal.Width)) + geom_point(aes(color = Species)) Usually it is helpful to store the main portion of the plot in a variable and add on the layers. The code below achieves the same output as above: sepal_plot &lt;- ggplot(data = iris, mapping = aes(x = Sepal.Length, y = Sepal.Width)) sepal_plot + geom_point(aes(color = Species)) 4.5 Markdown etiquette I’m seeing that my R Markdown file is getting a little messy. Working with markdown and chunks can get out of hand, but there are some helpful tricks. First, consider naming your chunks as you go. If you combine this with headers, your work will be much more organized. Specifically, the little line at the bottom of the editor becomes much more useful. From this: To this: Just add a name to the start of each chunk: {r &lt;cool-code-chunk-name&gt;, &lt;chunk_option&gt; = TRUE} Now you can see what the chunks were about as well as get a sense of where you are in the document. Just don’t forget, it is a space after the r and commas for the other chunk options you may have like eval or echo. For more info, see our section on communicating results. 4.6 Overlapping data Eagle-eyed viewers may notice that we seem to be a few points short. We should be seeing 150 points, but we only see 117 (yes, I counted). Where are those 33 missing points? They are actually hiding behind other points. This dataset rounds to the nearest tenth of a centimeter, which is what is giving us those regular placings of the points. How did I know the data was in centimeters? Running ?iris in the console of course! Ah, you ask a silly question, you get a silly answer. # This plot hides some of the points ggplot(data = iris, mapping = aes(x = Sepal.Length, y = Sepal.Width)) + geom_point(aes(color = Species)) What’s the culprit? The color aesthetic. The color by default is opaque and will hide any points that are behind it. As a rule, it is always beneficial to reduce the opacity a little no matter what to avoid this problem. To do this, change the alpha value to something other than it’s default 1, like 0.5. ggplot(data = iris, mapping = aes(x = Sepal.Length, y = Sepal.Width)) + geom_point(aes(color = Species, alpha = 0.5)) Okay…a couple things with this. 4.6.1 First: the legend First, did you notice the new addition to the legend? That looks silly! Why did that show up? Well, when we added the alpha into aes(), we got a new legend. Let’s look at what we are doing with geom_point(). Specifically, this is saying how we should map the color and alpha: geom_point(mapping = aes(color = Species, alpha = 0.5)) So, we are mapping these given aesthetics, color and alpha, to certain values. ggplot knows that usually the aesthetic mapping will vary since you are probably passing in data that varies, so it will create a legend for each mapping. However, we don’t need a legend for the alpha: we explicitly set it to be 0.5. To fix this, we can pull alpha out of aes and instead treat it like an attribute: ggplot(data = iris, mapping = aes(x = Sepal.Length, y = Sepal.Width)) + geom_point(aes(color = Species), alpha = 0.5) No more legend. So, in ggplot, there is a difference between where an aesthetic is placed. It is also called MAPPING an aesthetic (making it vary with data inside aes) or SETTING an aesthetic (make it a constant attribute across all datapoints outside of aes). 4.6.2 Second: jittering Secondly, did this alpha trick really help us? Are we able to see anything in the plot in an easier way? Not really. Since the points perfectly overlap, the opacity difference doesn’t help us much. Usually, opacity will work, but here the data is so regular that we don’t gain anything in the perception department. We can fix this by introducing some jitter to the datapoints. Jitter adds a little random noise and moves the datapoints so that they don’t fully overlap: ggplot(data = iris, mapping = aes(x = Sepal.Length, y = Sepal.Width)) + geom_point(aes(color = Species), alpha = 0.5, position = &quot;jitter&quot;) Consider your motives when using jittering. You are by definition altering the data, but it may be beneficial in some situations. 4.6.3 Aside: example where alpha blending works We are dealing with a case where jittering works best to see the data, while changing the alpha doesn’t help us much. Here’s a quick example where opacity using alpha might be more directly helpful. # lib for arranging plots side by side library(gridExtra) # make some normally distributed data x_points &lt;- rnorm(n = 10000, mean = 0, sd = 2) y_points &lt;- rnorm(n = 10000, mean = 6, sd = 2) df &lt;- data.frame(x_points, y_points) # plot with/without changed alpha plt1 &lt;- ggplot(df, aes(x_points, y_points)) + geom_point() + ggtitle(&quot;Before (alpha = 1)&quot;) plt2 &lt;- ggplot(df, aes(x_points, y_points)) + geom_point(alpha = 0.1) + ggtitle(&quot;After (alpha = 0.1)&quot;) # arrange plots gridExtra::grid.arrange(plt1, plt2, ncol = 2, nrow = 1) Here it is much easier to see where the dataset is concentrated. 4.7 Formatting for presentation Let’s say we have finished this plot and we are ready to present it to other people: We should clean it up a bit so it can stand on its own. 4.8 Alter appearance First, let’s make the x/y labels a little cleaner and more descriptive: ggplot(data = iris, mapping = aes(x = Sepal.Length, y = Sepal.Width)) + geom_point(aes(color = Species), alpha = 0.5, position = &quot;jitter&quot;) + xlab(&quot;Sepal Length (cm)&quot;) + ylab(&quot;Sepal Width (cm)&quot;) Next, add a title that encapsulates the plot: ggplot(data = iris, mapping = aes(x = Sepal.Length, y = Sepal.Width)) + geom_point(aes(color = Species), alpha = 0.5, position = &quot;jitter&quot;) + xlab(&quot;Sepal Length (cm)&quot;) + ylab(&quot;Sepal Width (cm)&quot;) + ggtitle(&quot;Sepal Dimensions in Different Species of Iris Flowers&quot;) And make the points a little bigger: ggplot(data = iris, mapping = aes(x = Sepal.Length, y = Sepal.Width)) + geom_point(aes(color = Species), size = 3, alpha = 0.5, position = &quot;jitter&quot;) + xlab(&quot;Sepal Length (cm)&quot;) + ylab(&quot;Sepal Width (cm)&quot;) + ggtitle(&quot;Sepal Dimensions in Different Species of Iris Flowers&quot;) Now it’s looking presentable. 4.9 Consider themes It may be better for your situation to change the theme of the plot (the background, axes, etc.; the “accessories” of the plot). Explore what different themes can offer and pick one that is right for you. base_plot &lt;- ggplot(data = iris, mapping = aes(x = Sepal.Length, y = Sepal.Width)) + geom_point(aes(color = Species), size = 3, alpha = 0.5, position = &quot;jitter&quot;) + xlab(&quot;Sepal Length (cm)&quot;) + ylab(&quot;Sepal Width (cm)&quot;) + ggtitle(&quot;Sepal Dimensions in Different Species of Iris Flowers&quot;) base_plot base_plot + theme_light() base_plot + theme_minimal() base_plot + theme_classic() base_plot + theme_void() I’m going to go with theme_minimal() this time. So here we are! We got a lovely scatterplot ready to show the world! 4.10 Going deeper We have just touched the surface of ggplot and dipped our toes into grammar of graphics. If you want to go deeper, I highly recommend the DataCamp courses on Data Visualization with ggplot2 with Rick Scavetta. There are three parts and they are quite dense, but the first part is definitely worth checking out. 4.11 Helpful links RStudio ggplot2 Cheat Sheet DataCamp: Mapping aesthetics to things in ggplot R Markdown Reference Guide R for Data Science "],
["missingTS.html", "5 Time Series with Missing Data 5.1 Overview 5.2 Motivation 5.3 Visualizing missing values 5.4 Imputing missing values 5.5 Further reading", " 5 Time Series with Missing Data This chapter originated as a community contribution created by sdt2134 This page is a work in progress. We appreciate any input you may have. If you would like to help improve this page, consider contributing to our repo. 5.1 Overview For data scientists, data preparation could easily be the second most frustrating task, right after explaining their models to other departments. Missing value treatment is a key part of data preparation and knowing how to handle it well can reduce the excruciating pain one feels after seeing a poor RMSE. The chapter on missing data talks about some of the ways you could handle missing data in your dataset; this walkthrough takes it further focusing specifically on timeseries data. 5.2 Motivation Why should you care when you have mean, median &amp; mode? You should care because time series problems are not that straight-forward. Most often time series are accompanied by forecasting tasks and most algorithms won’t allow missing data. Imputation using mean, median &amp; mode might hide trends or seasonal patterns whereas removing missing data points altogether might reduce information contained in other features for those cases. ImputeTS in R provides a bunch of functions to visualize and approximate missing values with high precision. But first you must ask yourself two questions: Is there any identifiable reason for it? Are they missing at random? Is there any identifiable reason for it? Let’s take the example of a bakery. You are forecasting daily cake sales and find missing data is linked to holidays. How to impute? One way could be to fill with zeroes and create a flag that could help your forecasting algorithm understand this pattern. If sales are missing if your cakes were out of stock or the baker was on leave such flags won’t work as you cannot predict these events in the future. Imputation is ideal for treating such cases. What if they are missing at random? You have only one option - imputation. Let’s go through a time series exercise where we have to decompose it when missing values are present. Dataset : a10 “Monthly anti-diabetic drug sales in Australia from 1992 to 2008” For this walkthrough we will use two copies of the a10 dataset. Here’s the original dataset from the fpp package complete_a10 &lt;- fpp::a10 Let’s create missing values and check the performance of various imputation functions on hidden values. set.seed(134) missatrand_a10 &lt;- complete_a10 missatrand_a10[sample(length(complete_a10),0.2*length(complete_a10))] &lt;- NA 5.2.0.1 Let’s analyse this timeseries graphically plot(missatrand_a10) Looks like the series has multiplicative seasonality. Let’s transform it into additive to see if seasonality appears more clearly. plot(log(missatrand_a10)) Wow, it shows a clear seasonal pattern with an increasing trend. 5.2.0.2 What if we decompose it into into its components plot(decompose(missatrand_a10, type = &quot;multiplicative&quot;)) ## Error in na.omit.ts(x): time series contains internal NAs Not so fast. As mentioned above, we must treat the missing values before we do this. Enough said let’s impute this missing piece into our toolkit! 5.3 Visualizing missing values library(imputeTS) plotNA.distribution(missatrand_a10) Let’s get a summary of the missing values. statsNA(missatrand_a10) ## [1] &quot;Length of time series:&quot; ## [1] 204 ## [1] &quot;-------------------------&quot; ## [1] &quot;Number of Missing Values:&quot; ## [1] 40 ## [1] &quot;-------------------------&quot; ## [1] &quot;Percentage of Missing Values:&quot; ## [1] &quot;19.6%&quot; ## [1] &quot;-------------------------&quot; ## [1] &quot;Stats for Bins&quot; ## [1] &quot; Bin 1 (51 values from 1 to 51) : 13 NAs (25.5%)&quot; ## [1] &quot; Bin 2 (51 values from 52 to 102) : 8 NAs (15.7%)&quot; ## [1] &quot; Bin 3 (51 values from 103 to 153) : 10 NAs (19.6%)&quot; ## [1] &quot; Bin 4 (51 values from 154 to 204) : 9 NAs (17.6%)&quot; ## [1] &quot;-------------------------&quot; ## [1] &quot;Longest NA gap (series of consecutive NAs)&quot; ## [1] &quot;3 in a row&quot; ## [1] &quot;-------------------------&quot; ## [1] &quot;Most frequent gap size (series of consecutive NA series)&quot; ## [1] &quot;1 NA in a row (occuring 29 times)&quot; ## [1] &quot;-------------------------&quot; ## [1] &quot;Gap size accounting for most NAs&quot; ## [1] &quot;1 NA in a row (occuring 29 times, making up for overall 29 NAs)&quot; ## [1] &quot;-------------------------&quot; ## [1] &quot;Overview NA series&quot; ## [1] &quot; 1 NA in a row: 29 times&quot; ## [1] &quot; 2 NA in a row: 4 times&quot; ## [1] &quot; 3 NA in a row: 1 times&quot; Are there any patterns in missingness, how many consecutive NA’s are there (gapsize), and how many missing values are accounted by a specific gapsize? plotNA.gapsize(missatrand_a10) 5.4 Imputing missing values 5.4.1 Generic methods : independent of time series’ temporal properties 5.4.1.1 Mean, median and mode This is a straight forward and simple method for interpolation. But given we are imputing the missing value by calculating the mean, we end up losing information around the trend and seasonality, leading to huge errors in imputation. Because of this reason, this method is best suited for data that is stationary. This function also allows us to use other measures like median and mode. 5.4.1.1.0.1 Method 1 imp &lt;- na.mean(missatrand_a10) p1&lt;-as.tibble(cbind(Date = as.yearmon(time(missatrand_a10)), missatrand = missatrand_a10,complete_a10 = complete_a10,imputed_val = imp))%&gt;% mutate(imputed_val = ifelse(is.na(missatrand),imputed_val,NA), complete_a10 = ifelse(is.na(missatrand),complete_a10,NA) )%&gt;% ggplot(aes(x=Date)) + #geom_line(aes(y=missatrand),color=&quot;red&quot;)+ geom_line(aes(y=missatrand),color = &quot;black&quot;)+ geom_point(aes(y=imputed_val),color = &quot;blue&quot;)+ geom_point(aes(y=complete_a10),color = &quot;red&quot;)+ ylab(&quot;Anti-diabetic drug sales&quot;)+ ggtitle(&quot;Imputed values (Blue); Real values (Red) &quot;)+ theme(plot.title = element_text(size = 10)) p2 &lt;- ggplot() + geom_line(aes(y = complete_a10-imp, x = as.yearmon(time(missatrand_a10)) )) + ylim(-10,10) + ylab(&quot;Errors&quot;)+ xlab(&quot;Date&quot;)+ ggtitle(paste(&quot;Errors in imputation&quot;))+ theme(plot.title = element_text(size = 10)) grid.arrange(p1, p2, ncol=2,top=&quot;Interpolation using mean&quot;) 5.4.1.2 Moving Averages As this function calculates moving averages based on the last n observations, it will generally be performing better than the last method. Moving averages work well when data has a linear trend. This function also allows us to use linear-weighted and exponentially-weighted moving averages. 5.4.1.2.0.1 Method 2 imp &lt;- na.ma(missatrand_a10) p1&lt;-as.tibble(cbind(Date = as.yearmon(time(missatrand_a10)), missatrand = missatrand_a10,complete_a10 = complete_a10,imputed_val = imp))%&gt;% mutate(imputed_val = ifelse(is.na(missatrand),imputed_val,NA), complete_a10 = ifelse(is.na(missatrand),complete_a10,NA) )%&gt;% ggplot(aes(x=Date)) + #geom_line(aes(y=missatrand),color=&quot;red&quot;)+ geom_line(aes(y=missatrand),color = &quot;black&quot;)+ geom_point(aes(y=imputed_val),color = &quot;blue&quot;)+ geom_point(aes(y=complete_a10),color = &quot;red&quot;)+ ylab(&quot;Anti-diabetic drug sales&quot;)+ ggtitle(&quot;Imputed values (Blue); Real values (Red) &quot;)+ theme(plot.title = element_text(size = 10)) p2 &lt;- ggplot() + geom_line(aes(y = complete_a10-imp, x = as.yearmon(time(missatrand_a10)) )) + ylim(-10,10) + ylab(&quot;Errors&quot;)+ xlab(&quot;Date&quot;)+ ggtitle(paste(&quot;Errors in imputation&quot;))+ theme(plot.title = element_text(size = 10)) grid.arrange(p1, p2, ncol=2,top=&quot;Interpolation using n-Moving Averages&quot;) 5.4.2 Time series specific methods 5.4.2.1 Kalman smoothing with auto.arima This is a more advanced function for interpolation and requires higher computation time. It uses Kalman Smoothing on ARIMA model to impute the missing values. Structural time series models are another type of model that can be used to impute missing values using this function . 5.4.2.1.0.1 Method 3 imp &lt;- na.kalman(missatrand_a10,model = &quot;auto.arima&quot;) p1&lt;-as.tibble(cbind(Date = as.yearmon(time(missatrand_a10)), missatrand = missatrand_a10,complete_a10 = complete_a10,imputed_val = imp))%&gt;% mutate(imputed_val = ifelse(is.na(missatrand),imputed_val,NA), complete_a10 = ifelse(is.na(missatrand),complete_a10,NA) )%&gt;% ggplot(aes(x=Date)) + #geom_line(aes(y=missatrand),color=&quot;red&quot;)+ geom_line(aes(y=missatrand),color = &quot;black&quot;)+ geom_point(aes(y=imputed_val),color = &quot;blue&quot;)+ geom_point(aes(y=complete_a10),color = &quot;red&quot;)+ ylab(&quot;Anti-diabetic drug sales&quot;)+ ggtitle(&quot;Imputed values (Blue); Real values (Red) &quot;)+ theme(plot.title = element_text(size = 10)) p2 &lt;- ggplot() + geom_line(aes(y = complete_a10-imp, x = as.yearmon(time(missatrand_a10)) )) + ylim(-10,10) + ylab(&quot;Errors&quot;)+ xlab(&quot;Date&quot;)+ ggtitle(paste(&quot;Errors in imputation&quot;))+ theme(plot.title = element_text(size = 10)) grid.arrange(p1, p2, ncol=2,top=&quot;Interpolation using Auto.arima&quot;) 5.4.2.2 Seasonal splitting This function interpolates missing values by splitting the data by seasons and performing imputation on the resulting datasets. Another similar function that works based on the seasonality component in this package is na.seadec() which deseasonalizes the data, performs imputation, and adds the seasonal component back again. 5.4.2.2.0.1 Method 4 imp &lt;- na.seasplit(missatrand_a10) p1&lt;-as.tibble(cbind(Date = as.yearmon(time(missatrand_a10)), missatrand = missatrand_a10,complete_a10 = complete_a10,imputed_val = imp))%&gt;% mutate(imputed_val = ifelse(is.na(missatrand),imputed_val,NA), complete_a10 = ifelse(is.na(missatrand),complete_a10,NA) )%&gt;% ggplot(aes(x=Date)) + #geom_line(aes(y=missatrand),color=&quot;red&quot;)+ geom_line(aes(y=missatrand),color = &quot;black&quot;)+ geom_point(aes(y=imputed_val),color = &quot;blue&quot;)+ geom_point(aes(y=complete_a10),color = &quot;red&quot;)+ ylab(&quot;Anti-diabetic drug sales&quot;)+ ggtitle(&quot;Imputed values (Blue); Real values (Red) &quot;)+ theme(plot.title = element_text(size = 10)) p2 &lt;- ggplot() + geom_line(aes(y = complete_a10-imp, x = as.yearmon(time(missatrand_a10)) )) + ylim(-10,10) + ylab(&quot;Errors&quot;)+ xlab(&quot;Date&quot;)+ ggtitle(paste(&quot;Errors in imputation&quot;))+ theme(plot.title = element_text(size = 10)) grid.arrange(p1, p2, ncol=2,top=&quot;Seasonally splitted interpolation&quot;) 5.5 Further reading Details about the imputeTS package can be found here. imputeTS To learn more about time series, decomposition, forecasting and more check Rob J. Hyndman’s notes from otext "],
["bar.html", "6 Chart: Bar Chart 6.1 Overview 6.2 tl;dr 6.3 Simple examples 6.4 Theory 6.5 When to use 6.6 Considerations 6.7 Modifications 6.8 External resources", " 6 Chart: Bar Chart 6.1 Overview This section covers how to make bar charts 6.2 tl;dr I want a nice example. Not tomorrow, not after breakfast. NOW! Here’s a bar chart showing the survival rates of passengers aboard the RMS Titanic: And here’s the code: library(datasets) # data library(ggplot2) # plotting library(dplyr) # manipulation # Combine Children and Adult stats together ship_grouped &lt;- as.data.frame(Titanic) %&gt;% group_by(Class, Sex, Survived) %&gt;% summarise(Total = sum(Freq)) ggplot(ship_grouped, aes(x = Survived, y = Total, fill = Sex)) + geom_bar(position = &quot;dodge&quot;, stat = &quot;identity&quot;) + geom_text(aes(label = Total), position = position_dodge(width = 0.9), vjust = -0.4, color = &quot;grey68&quot;) + facet_wrap(~Class) + # formatting ylim(0, 750) + ggtitle(&quot;Don&#39;t Be A Crew Member On The Titanic&quot;, subtitle = &quot;Survival Rates of Titanic Passengers by Class and Gender&quot;) + scale_fill_manual(values = c(&quot;#b2df8a&quot;, &quot;#a6cee3&quot;)) + labs(y = &quot;Passenger Count&quot;, caption = &quot;Source: titanic::titanic_train&quot;) + theme(plot.title = element_text(face = &quot;bold&quot;)) + theme(plot.subtitle = element_text(face = &quot;bold&quot;, color = &quot;grey35&quot;)) + theme(plot.caption = element_text(color = &quot;grey68&quot;)) For more info on this dataset, type ?datasets::Titanic into the console. 6.3 Simple examples My eyes were bigger than my stomach. Much simpler please! Let’s use the HairEyeColor dataset. To start, we will just look at the different categories of hair color among females: colors &lt;- as.data.frame(HairEyeColor) # just female hair color, using dplyr colors_female_hair &lt;- colors %&gt;% filter(Sex == &quot;Female&quot;) %&gt;% group_by(Hair) %&gt;% summarise(Total = sum(Freq)) # take a look at data head(colors_female_hair) ## # A tibble: 4 x 2 ## Hair Total ## &lt;fct&gt; &lt;dbl&gt; ## 1 Black 52 ## 2 Brown 143 ## 3 Red 37 ## 4 Blond 81 Now let’s make some graphs with this data. 6.3.1 Bar graph using base R barplot(colors_female_hair[[&quot;Total&quot;]], names.arg = colors_female_hair[[&quot;Hair&quot;]], main = &quot;Bar Graph Using Base R&quot;) We recommend using Base R only for simple bar graphs for yourself. Like all of Base R, it is simple to setup. Note: Base R expects a vector or matrix, hence the double brackets in the barplot call (gets columns as lists). 6.3.2 Bar graph using ggplot2 library(ggplot2) # plotting ggplot(colors_female_hair, aes(x = Hair, y = Total)) + geom_bar(stat = &quot;identity&quot;) + ggtitle(&quot;Bar Graph Using ggplot2&quot;) Bar plots are very easy in ggplot2. You pass in a dataframe and let it know which parts you want to map to different aesthetics. Note: In this case, we have a table of values and want to plot them as explicit bar heights. Because of this, we specify the y aesthetic as the Total column, but we also have to specify stat = &quot;identity&quot; in geom_bar() so it knows to plot them correctly. Often you will have datasets where each row is one observation and you want to group them into bars. In that case, the y aesthetic and stat = &quot;identity&quot; do not have to be specified. 6.4 Theory For more info about plotting categorical data, check out Chapter 4 of the textbook. 6.5 When to use Bar Charts are best for categorical data. Often you will have a collection of factors that you want to split into different groups. 6.6 Considerations 6.6.1 Not for continuous data If you are finding that your bar graphs aren’t looking right, make sure your data is categorical and not continuous. If you want to plot continuous data using bars, that is what histograms are for! 6.7 Modifications These modifications assume you are using ggplot2. 6.7.1 Flip Bars To flip the orientation, just tack on coord_flip(): ggplot(colors_female_hair, aes(x = Hair, y = Total)) + geom_bar(stat = &quot;identity&quot;) + ggtitle(&quot;Bar Graph Using ggplot2&quot;) + coord_flip() 6.7.2 Reorder the bars With both base R and ggplot2 bars are drawn in alphabetical order for character data and in the order of factor levels for factor data. However, since the default order of levels for factor data is alphabetical, the bars will be alphabetical in both cases. Please see this tutorial for a detailed explanation on how bars should be ordered in a bar chart, and how the forcats package can help you accomplish the reordering. 6.7.3 Facet Wrap You can split the graph into small multiples using facet_wrap() (don’t forget the tilde, ~): ggplot(colors, aes(x = Sex, y = Freq)) + geom_bar(stat = &quot;identity&quot;) + facet_wrap(~Hair) 6.8 External resources Cookbook for R: Discussion on reordering the levels of a factor. DataCamp Exercise: Simple exercise on making bar graphs with ggplot2. ggplot2 cheatsheet: Always good to have close by. "],
["box.html", "7 Chart: Boxplot 7.1 Overview 7.2 tl;dr 7.3 Simple examples 7.4 Theory 7.5 When to use 7.6 Considerations 7.7 External resources", " 7 Chart: Boxplot 7.1 Overview This section covers how to make boxplots. 7.2 tl;dr I want a nice example and I want it NOW! Here’s a look at the weights of newborn chicks split by the feed supplement they received: And here’s the code: library(datasets) # data library(ggplot2) # plotting # reorder supplements supps &lt;- c(&quot;horsebean&quot;, &quot;linseed&quot;, &quot;soybean&quot;, &quot;meatmeal&quot;, &quot;sunflower&quot;, &quot;casein&quot;) # boxplot by feed supplement with jitter layer ggplot(chickwts, aes(x = factor(feed, levels = supps), y = weight)) + # plotting geom_boxplot(fill = &quot;#cc9a38&quot;, color = &quot;#473e2c&quot;) + geom_jitter(alpha = 0.2, width = 0.1, color = &quot;#926d25&quot;) + # formatting ggtitle(&quot;Casein Makes You Fat?!&quot;, subtitle = &quot;Boxplots of Chick Weights by Feed Supplement&quot;) + labs(x = &quot;Feed Supplement&quot;, y = &quot;Chick Weight (g)&quot;, caption = &quot;Source: datasets::chickwts&quot;) + theme(plot.title = element_text(face = &quot;bold&quot;)) + theme(plot.subtitle = element_text(face = &quot;bold&quot;, color = &quot;grey35&quot;)) + theme(plot.caption = element_text(color = &quot;grey68&quot;)) For more info on this dataset, type ?datasets::chickwts into the console. 7.3 Simple examples Okay…much simpler please. Let’s use the airquality dataset from the datasets package: library(datasets) head(airquality, n = 5) ## Ozone Solar.R Wind Temp Month Day ## 1 41 190 7.4 67 5 1 ## 2 36 118 8.0 72 5 2 ## 3 12 149 12.6 74 5 3 ## 4 18 313 11.5 62 5 4 ## 5 NA NA 14.3 56 5 5 7.3.1 Boxplot using base R # plot data boxplot(airquality, col = &#39;lightBlue&#39;, main = &quot;Base R Boxplots of airquality&quot;) Boxplots with Base R are super easy. Like histograms, boxplots only need the data. In this case, we passed a dataframe with six variables, so it made separate boxplots for each variable. You may not want to create boxplots for every variable, in which case you could specify the variables individually or use filter from the dplyr package. 7.3.2 Boxplot using ggplot2 # import ggplot library(ggplot2) # plot data g1 &lt;- ggplot(stack(airquality), aes(x = ind, y = values)) + geom_boxplot(fill = &quot;lightBlue&quot;) + # extra formatting labs(x = &quot;&quot;) + ggtitle(&quot;ggplot2 Boxplots of airquality&quot;) g1 ## Warning: Removed 44 rows containing non-finite values (stat_boxplot). ggplot2 requires data to be mapped to the x and y aesthetics. Here we use the stack function to combine each column of the airquality dataframe. Reading the documentation for the stack function (?utils::stack), we see the new stacked dataframe has two columns: values and ind, which we use to create the boxplots. Notice: ggplot2 warns us that it is ignoring “non-finite values”, which are the NA’s in the dataset. 7.4 Theory Here’s a quote by Hadley Wickham that sums up boxplots nicely: The boxplot is a compact distributional summary, displaying less detail than a histogram or kernel density, but also taking up less space. Boxplots use robust summary statistics that are always located at actual data points, are quickly computable (originally by hand), and have no tuning parameters. They are particularly useful for comparing distributions across groups. - Hadley Wickham Another important use of the boxplot is in showing outliers. A boxplot shows how much of an outlier a data point is with quartiles and fences. Use the boxplot when you have data with outliers so that they can be exposed. What it lacks in specificity it makes up with its ability to clearly summarize large data sets. For more info about boxplots and continuous variables, check out Chapter 3 of the textbook. 7.5 When to use Boxplots should be used to display continuous variables. They are particularly useful for identifying outliers and comparing different groups. Aside: Boxplots may even help you convince someone you are their outlier (If you like it when people over-explain jokes, here is why that comic is funny.). 7.6 Considerations 7.6.1 Flipping orientation Often you want boxplots to be horizontal. Super easy to do: just tack on coord_flip(): # g1 plot from above (5.3.2) g1 + coord_flip() ## Warning: Removed 44 rows containing non-finite values (stat_boxplot). 7.6.2 NOT for categorical data Boxplots are great, but they do NOT work with categorical data. Make sure your variable is continuous before using boxplots. Here’s an example of what not to do: library(likert) # data library(dplyr) # data manipulation # load/format data data(pisaitems) pisa &lt;- pisaitems[1:100, 2:7] %&gt;% dplyr::mutate_all(as.integer) %&gt;% dplyr::filter(complete.cases(.)) # create theme theme &lt;- theme(plot.title = element_text(face = &quot;bold&quot;)) + theme(plot.subtitle = element_text(face = &quot;bold&quot;, color = &quot;grey35&quot;)) + theme(plot.caption = element_text(color = &quot;grey68&quot;)) # create plot plot &lt;- ggplot(stack(pisa), aes(x = ind, y = values)) + geom_boxplot(fill = &quot;#9B3535&quot;) + ggtitle(&quot;Don&#39;t Plot Boxplots of Categorical Variables Like This&quot;, subtitle = &quot;...seriously don&#39;t. Here, I&#39;ll make it red so it looks scary:&quot;) + labs(x = &quot;Assessment Code&quot;, y = &quot;Values&quot;, caption = &quot;Source: likert::pisaitems&quot;) # bad boxplot plot + theme 7.7 External resources Tukey, John W. 1977. Exploratory Data Analysis. Addison-Wesley. (Chapter 2): the primary source in which boxplots are first presented. DataCamp: Quick Exercise on Boxplots: a simple example of making boxplots from a dataset. Article on boxplots with ggplot2: An excellent collection of code examples on how to make boxplots with ggplot2. Covers layering, working with legends, faceting, formatting, and more. If you want a boxplot to look a certain way, this article will help. Boxplots with plotly package: boxplot examples using the plotly package. These allow for a little interactivity on hover, which might better explain the underlying statistics of your plot. ggplot2 Boxplot: Quick Start Guide: Article from STHDA on making boxplots using ggplot2. Excellent starting point for getting immediate results and custom formatting. ggplot2 cheatsheet: Always good to have close by. Hadley Wickhan and Lisa Stryjewski on boxplots: good for understanding basics of more complex boxplots and some of the history behind them. "],
["heatmap.html", "8 Chart: Heatmap 8.1 Overview 8.2 tl;dr 8.3 Simple examples 8.4 Theory 8.5 External resources", " 8 Chart: Heatmap 8.1 Overview This section covers how to make heatmaps. 8.2 tl;dr Enough with these simple examples! I want a complicated one! Here’s a heatmap of occupational categories of sons and fathers in the US, UK, and Japan: And here’s the code: library(vcdExtra) # dataset library(dplyr) # manipulation library(ggplot2) # plotting library(viridis) # color palette # format data orderedclasses &lt;- c(&quot;Farm&quot;, &quot;LoM&quot;, &quot;UpM&quot;, &quot;LoNM&quot;, &quot;UpNM&quot;) mydata &lt;- Yamaguchi87 mydata$Son &lt;- factor(mydata$Son, levels = orderedclasses) mydata$Father &lt;- factor(mydata$Father, levels = orderedclasses) japan &lt;- mydata %&gt;% filter(Country == &quot;Japan&quot;) uk &lt;- mydata %&gt;% filter(Country == &quot;UK&quot;) us &lt;- mydata %&gt;% filter(Country == &quot;US&quot;) # convert to % of country and class total mydata_new &lt;- mydata %&gt;% group_by(Country, Father) %&gt;% mutate(Total = sum(Freq)) %&gt;% ungroup() # make custom theme theme_heat &lt;- theme_classic() + theme(axis.line = element_blank(), axis.ticks = element_blank()) # basic plot plot &lt;- ggplot(mydata_new, aes(x = Father, y = Son)) + geom_tile(aes(fill = Freq/Total), color = &quot;white&quot;) + coord_fixed() + facet_wrap(~Country) + theme_heat # plot with text overlay and viridis color palette plot + geom_text(aes(label = round(Freq/Total, 1)), color = &quot;white&quot;) + scale_fill_viridis() + # formatting ggtitle(&quot;Like Father, Like Son&quot;, subtitle = &quot;Heatmaps of occupational categories for fathers and sons, by country&quot;) + labs(caption = &quot;Source: vcdExtra::Yamaguchi87&quot;) + theme(plot.title = element_text(face = &quot;bold&quot;)) + theme(plot.subtitle = element_text(face = &quot;bold&quot;, color = &quot;grey35&quot;)) + theme(plot.caption = element_text(color = &quot;grey68&quot;)) For more info on this dataset, type ?vcdExtra::Yamaguchi87 into the console. 8.3 Simple examples Too complicated! Simplify, man! 8.3.1 Heatmap of two-dimensional bin counts For this heatmap, we will use the SpeedSki dataset. Only two variables, x and y are needed for two-dimensional bin count heatmaps. The third variable–i.e., the color–represents the bin count of points in the region it covers. Think of it as a two-dimensional histogram. To create a heatmap, simply substitute geom_point() with geom_bin2d(): library(ggplot2) # plotting library(GDAdata) # data (SpeedSki) ggplot(SpeedSki, aes(Year, Speed)) + geom_bin2d() 8.3.2 Heat map of dataframe To get a visual sense of the dataframe, you can use a heatmap. You can also look into scaling the columns to get a sense of your data on a common scale. In this example, we use geom_tile to graph all cells in the dataframe and color them by their value: library(pgmm) # data library(tidyverse) # processing/graphing library(viridis) # color palette data(wine) # convert to column, value wine_new &lt;- wine %&gt;% rownames_to_column() %&gt;% gather(colname, value, -rowname) ggplot(wine_new, aes(x = rowname, y = colname, fill = value)) + geom_tile() + scale_fill_viridis() + ggtitle(&quot;Italian Wine Dataframe&quot;) # only difference from above is scaling wine_scaled &lt;- data.frame(scale(wine)) %&gt;% rownames_to_column() %&gt;% gather(colname, value, -rowname) ggplot(wine_scaled, aes(x = rowname, y = colname, fill = value)) + geom_tile() + scale_fill_viridis() + ggtitle(&quot;Italian Wine Dataframe, Scaled&quot;) 8.3.3 Modifications You can change the color palette by specifying it explicitly in your chain of ggplot function calls. The bin width can be added inside the geom_bin2d() function call: library(viridis) # viridis color palette # create plot g1 &lt;- ggplot(SpeedSki, aes(Year, Speed)) + scale_fill_viridis() # modify color # show plot g1 + geom_bin2d(binwidth = c(5, 5)) # modify bin width Here are some other examples: # larger bin width g1 + geom_bin2d(binwidth = c(10, 10)) # hexagonal bins g1 + geom_hex(binwidth = c(5, 5)) # hexagonal bins + scatterplot layer g1 + geom_hex(binwidth = c(5, 5), alpha = .4) + geom_point(size = 2, alpha = 0.8) # hexagonal bins with custom color gradient/bin count ggplot(SpeedSki, aes(Year, Speed)) + scale_fill_gradient(low = &quot;#cccccc&quot;, high = &quot;#09005F&quot;) + # color geom_hex(bins = 10) # number of bins horizontally/vertically 8.4 Theory Heat maps are like a combination of scatterplots and histograms: they allow you to compare different parameters while also seeing their relative distributions. While heatmaps are visually striking, there are often better choices to get your point across. For more info, checkout this DataCamp section on heatmaps and alternatives. 8.5 External resources R Graph Gallery: Heatmaps: Has examples of creating heatmaps with the heatmap() function. How to make a simple heatmap in ggplot2: Create a heatmap with geom_tile(). "],
["histo.html", "9 Chart: Histogram 9.1 Overview 9.2 tl;dr 9.3 Simple examples 9.4 Theory 9.5 Types of histrograms 9.6 Parameters 9.7 External resources", " 9 Chart: Histogram 9.1 Overview This section covers how to make histograms. 9.2 tl;dr Gimme a full-fledged example! Here’s an application of histograms that looks at how the beaks of Galapagos finches changed due to external factors: And here’s the code: library(Sleuth3) # data library(ggplot2) # plotting # load data finches &lt;- Sleuth3::case0201 # finch histograms by year with overlayed density curves ggplot(finches, aes(x = Depth, y = ..density..)) + # plotting geom_histogram(bins = 20, colour = &quot;#80593D&quot;, fill = &quot;#9FC29F&quot;, boundary = 0) + geom_density(color = &quot;#3D6480&quot;) + facet_wrap(~Year) + # formatting ggtitle(&quot;Severe Drought Led to Finches with Bigger Chompers&quot;, subtitle = &quot;Beak Depth Density of Galapagos Finches by Year&quot;) + labs(x = &quot;Beak Depth (mm)&quot;, caption = &quot;Source: Sleuth3::case0201&quot;) + theme(plot.title = element_text(face = &quot;bold&quot;)) + theme(plot.subtitle = element_text(face = &quot;bold&quot;, color = &quot;grey35&quot;)) + theme(plot.caption = element_text(color = &quot;grey68&quot;)) For more info on this dataset, type ?Sleuth3::case0201 into the console. 9.3 Simple examples Whoa whoa whoa! Much simpler please! Let’s use a very simple dataset: # store data x &lt;- c(50, 51, 53, 55, 56, 60, 65, 65, 68) 9.3.1 Histogram using base R # plot data hist(x, col = &quot;lightblue&quot;, main = &quot;Base R Histogram of x&quot;) For the Base R histogram, it’s advantages are in it’s ease to setup. In truth, all you need to plot the data x in question is hist(x), but we included a little color and a title to make it more presentable. Full documentation on hist() can be found here 9.3.2 Histogram using ggplot2 # import ggplot library(ggplot2) # must store data as dataframe df &lt;- data.frame(x) # plot data ggplot(df, aes(x)) + geom_histogram(color = &quot;grey&quot;, fill = &quot;lightBlue&quot;, binwidth = 5, center = 52.5) + ggtitle(&quot;ggplot2 histogram of x&quot;) The ggplot version is a little more complicated on the surface, but you get more power and control as a result. Note: as shown above, ggplot expects a dataframe, so if you are getting an error where “R doesn’t know what to do” like this: ggplot dataframe error make sure you are using a dataframe. 9.4 Theory Generally speaking, the histogram is one of many options for displaying continuous data. The histogram is clear and quick to make. Histograms are relatively self-explanatory: they show your data’s empirical distribution within a set of intervals. Histograms can be employed on raw data to quickly show the distribution without much manipulation. Use a histogram to get a basic sense of the distribution with minimal processing necessary. For more info about histograms and continuous variables, check out Chapter 3 of the textbook. 9.5 Types of histrograms Use a histogram to show the distribution of one continuous variable. The y-scale can be represented in a variety of ways to express different results: 9.5.1 Frequency or count y = number of values that fall in each bin 9.5.2 Relative frequency historgram y = number of values that fall in each bin / total number of values 9.5.3 Cumulative frequency histogram y = total number of values &lt;= (or &lt;) right boundary of bin 9.5.4 Density y = relative frequency / binwidth 9.6 Parameters 9.6.1 Bin boundaries Be mindful of the boundaries of the bins and whether a point will fall into the left or right bin if it is on a boundary. # format layout op &lt;- par(mfrow = c(1, 2), las = 1) # right closed hist(x, col = &quot;lightblue&quot;, ylim = c(0, 4), xlab = &quot;right closed ex. (55, 60]&quot;, font.lab = 2) # right open hist(x, col = &quot;lightblue&quot;, right = FALSE, ylim = c(0, 4), xlab = &quot;right open ex. [55, 60)&quot;, font.lab = 2) 9.6.2 Bin number The default bin number of 30 in ggplot2 is not always ideal, so consider altering it if things are looking strange. You can specify the width explicitly with binwidth or provide the desired number of bins with bins. # default...note the pop-up about default bin number ggplot(finches, aes(x = Depth)) + geom_histogram() + ggtitle(&quot;Default with pop-up about bin number&quot;) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. Here are examples of changing the bins using the two ways described above: # using binwidth p1 &lt;- ggplot(finches, aes(x = Depth)) + geom_histogram(binwidth = 0.5, boundary = 6) + ggtitle(&quot;Changed binwidth value&quot;) # using bins p2 &lt;- ggplot(finches, aes(x = Depth)) + geom_histogram(bins = 48, boundary = 6) + ggtitle(&quot;Changed bins value&quot;) # format plot layout library(gridExtra) grid.arrange(p1, p2, ncol = 2) 9.6.3 Bin alignment Make sure the axes reflect the true boundaries of the histogram. You can use boundary to specify the endpoint of any bin or center to specify the center of any bin. ggplot2 will be able to calculate where to place the rest of the bins (Also, notice that when the boundary was changed, the number of bins got smaller by one. This is because by default the bins are centered and go over/under the range of the data.) df &lt;- data.frame(x) # default alignment ggplot(df, aes(x)) + geom_histogram(binwidth = 5, fill = &quot;lightBlue&quot;, col = &quot;black&quot;) + ggtitle(&quot;Default Bin Alignment&quot;) # specify alignment with boundary p3 &lt;- ggplot(df, aes(x)) + geom_histogram(binwidth = 5, boundary = 60, fill = &quot;lightBlue&quot;, col = &quot;black&quot;) + ggtitle(&quot;Bin Alignment Using boundary&quot;) # specify alignment with center p4 &lt;- ggplot(df, aes(x)) + geom_histogram(binwidth = 5, center = 67.5, fill = &quot;lightBlue&quot;, col = &quot;black&quot;) + ggtitle(&quot;Bin Alignment Using center&quot;) # format layout library(gridExtra) grid.arrange(p3, p4, ncol = 2) Note: Don’t use both boundary and center for bin alignment. Just pick one. 9.7 External resources DataCamp ggplot2 Histograms Exercise: Simple interactive example of histograms with ggplot2 DataCamp Histogram with Basic R: “Tutorial for new R users whom need an accessible and easy-to-understand resource on how to create their own histogram with basic R.” ’Nuff said. DataCamp Histogram with ggplot2: Great article on making histograms with ggplot2. hist documentation: base R histogram documentation page. ggplot2 cheatsheet: Always good to have close by. "],
["mosaic.html", "10 Chart: Mosaic 10.1 Overview 10.2 tl;dr 10.3 Simple Example Walkthrough 10.4 Mosaic using base R 10.5 Mosaic using ggplot 10.6 Theory 10.7 When to use 10.8 Considerations 10.9 External resources", " 10 Chart: Mosaic This chapter originated as a community contribution created by harin This page is a work in progress. We appreciate any input you may have. If you would like to help improve this page, consider contributing to our repo. 10.1 Overview This section covers how to make Mosaic plots 10.2 tl;dr library(vcd) mosaic(Favorite ~ Age + Music, labeling = labeling_border( abbreviate_labs = c(3, 10, 6), rot_labels=c(0,0,-45) ), direction=c(&#39;v&#39;,&#39;v&#39;,&#39;h&#39;), # Age = Vertical, Music = Vertical, Favoriate = Horizonal (a.k.a DoubleDecker) gp = gpar(fill=c(&#39;lightblue&#39;, &#39;gray&#39;)), df) 10.3 Simple Example Walkthrough 10.3.1 Order of splits It is best to draw mosaic plots incrementally: start with splitting on one variable and then add additional variables one at a time. The full mosaic plot will have one split per variable. Important: if your data is in a data frame (see above), the count column must be called Freq. Split on Age only: library(vcd) mosaic(~Age, df) Split on Age, then Music: mosaic(Music ~ Age, df) Note that the first split is between “young” and “old”, while the second set of splits divides each age group into “classical” and “rock”. Split on Age, then Music, then Favorite: mosaic(Favorite ~ Age + Music, df) 10.3.2 Direction of splits Note that in the previous example, the direction of the splits is as follows: Age – horizontal split Music – vertical split Favorite – horizontal split This is the default direction pattern: alternating directions beginning with horizontal. Therefore we get the same plot with the following: mosaic(Favorite ~ Age + Music, direction = c(&quot;h&quot;, &quot;v&quot;, &quot;h&quot;), df) The directions can be altered as desired. For example, to create a doubledecker plot, make all splits vertical except the last one: mosaic(Favorite ~ Age + Music, direction = c(&quot;v&quot;, &quot;v&quot;, &quot;h&quot;), df) Note that the direction vector is in order of splits (Age, Music, Favorite), not in the order in which the variables appear in the formula, where the last variable to be split is listed first, before the “~”. 10.3.3 Options 10.3.3.1 Fill color: library(grid) # needed for gpar mosaic(Favorite ~ Age + Music, gp = gpar(fill = c(&quot;lightblue&quot;, &quot;blue&quot;)), df) 10.3.3.2 Rotate labels: mosaic(Favorite ~ Age + Music, labeling = labeling_border(rot_labels = c(45, -45, 0, 0)), df) The rot_labels = vector sets the rotation in degrees on the four sides of the plot in this order: top, right, bottom, left. (Different from the typical base graphics order!) The default is rot_labels = c(0, 90, 0, 90). 10.3.3.3 Abbreviate labels: mosaic(Favorite ~ Age + Music, labeling = labeling_border(abbreviate_labs = c(3, 1, 6)), df) Labels are abbreviated in the order of the splits (as for direction =). The abbreviation algorithm appears to return the specified number of characters after vowels are eliminated (if necessary). For more formatting options, see &gt;?vcd::labeling_border. 10.3.3.4 Remove spacing between cells mosaic(Favorite ~ Age + Music, spacing = spacing_equal(sp = unit(0, &quot;lines&quot;)), df) For more details, see &gt;?vcd::spacings 10.3.3.5 Change border color (must also set fill(?)) mosaic(Favorite ~ Age + Music, gp = gpar(fill = c(&quot;lightblue&quot;, &quot;blue&quot;), col = &quot;white&quot;), spacing = spacing_equal(sp = unit(0, &quot;lines&quot;)), df) 10.4 Mosaic using base R library(vcdExtra) mosaicplot(xtabs(count ~ lake + sex, data=Alligator), main=&quot;&quot;) mosaicplot(xtabs(Freq ~ Favorite + Age + Music, data=df), main=&quot;&quot;, dir=c(&#39;h&#39;, &#39;v&#39;, &#39;v&#39;)) 10.4.1 Mosaic using vcd::doubledecker data(Arthritis) vcd::doubledecker(Improved ~ Treatment + Sex, data=Arthritis) vcd::doubledecker(Music ~ Favorite + Age, xtabs(Freq ~ Age + Music + Favorite, df)) 10.5 Mosaic using ggplot For a comprehensive overview of mosaic plot in ggplot check out the link below. https://cran.r-project.org/web/packages/ggmosaic/vignettes/ggmosaic.html library(ggmosaic) # equivalent to doing Favorite ~ Age + Music in vcd::mosaic with doubledecker style cut ggplot(df) + geom_mosaic( aes(x=product(Favorite, Age, Music), # cut from right to left weight=Freq, fill=Favorite ), divider=c(&quot;vspine&quot; , &quot;hspine&quot;, &quot;hspine&quot;) # equivalent to divider=ddecker() ) 10.6 Theory 10.7 When to use When you want to see the relationships in Multivariate Categorical Data 10.8 Considerations 10.8.1 Labels Legibility of the labels is problematic in mosaic plot especially when there are a lot of dimensions. This can be alleviated by - Abbreviate names - Rotating the labels 10.8.2 Aspect Ratio lengths are easier to judge than area, so try to use rectangles with same width or height Taller thinner rectangles are better (we are better at distinguishing length than area) 10.8.3 Gaps between rectangles No gap = most efficient However, a gap can help improve legibility, so try out different combinations Can have a gap at splits Can Vary gap size down the hierarchy 10.8.4 Color good for rates in the subgroup displaying residual emphasizing particular subgroup 10.9 External resources Chapter 7 of Graphical data analysis with R by Anthony Unwin Link: A comprehensive overview of mosaic plot in ggplot check out the link below. "],
["ridgeline.html", "11 Chart: Ridgeline Plots 11.1 Overview 11.2 tl;dr 11.3 Simple examples 11.4 Ridgeline Plots using ggridge 11.5 When to Use 11.6 Considerations 11.7 External Resources", " 11 Chart: Ridgeline Plots This chapter originated as a community contribution created by nehasaraf1994 This page is a work in progress. We appreciate any input you may have. If you would like to help improve this page, consider contributing to our repo. 11.1 Overview This section covers how to make ridgeline plots. 11.2 tl;dr I want a nice example and I want it NOW! Here’s a look at the dose of theophylline administered orally to the subject on which the concentration of theophylline is observed: Here is the code: library(&quot;ggridges&quot;) library(&quot;tidyverse&quot;) Theoph_data &lt;- Theoph ggplot(Theoph_data, aes(x=Dose,y=Subject,fill=Subject))+ geom_density_ridges_gradient(scale = 4, show.legend = FALSE) + theme_ridges() + scale_y_discrete(expand = c(0.01, 0)) + scale_x_continuous(expand = c(0.01, 0)) + labs(x = &quot;Dose of theophylline(mg/kg)&quot;,y = &quot;Subject #&quot;) + ggtitle(&quot;Density estimation of dosage given to various subjects&quot;) + theme(plot.title = element_text(hjust = 0.5)) For more info on this dataset, type ?datasets::Theoph into the console. 11.3 Simple examples Okay…much simpler please. Let’s use the Orange dataset from the datasets package: library(&quot;datasets&quot;) head(Orange, n=5) ## Grouped Data: circumference ~ age | Tree ## Tree age circumference ## 1 1 118 30 ## 2 1 484 58 ## 3 1 664 87 ## 4 1 1004 115 ## 5 1 1231 120 11.4 Ridgeline Plots using ggridge library(&quot;ggridges&quot;) library(&quot;tidyverse&quot;) ggplot(Orange, aes(x=circumference,y=Tree,fill = Tree))+ geom_density_ridges(scale = 2, alpha=0.5) + theme_ridges()+ scale_fill_brewer(palette = 4)+ scale_y_discrete(expand = c(0.8, 0)) + scale_x_continuous(expand = c(0.01, 0))+ labs(x=&quot;Circumference at Breast Height&quot;, y=&quot;Tree with ordering of max diameter&quot;)+ ggtitle(&quot;Density estimation of circumference of different types of Trees&quot;)+ theme(plot.title = element_text(hjust = 0.5)) ggridge uses two main geoms to plot the ridgeline density plots: “geom_density_ridges” and “geom_ridgeline”. They are used to plot the densities of categorical variable factors and see their distribution over a continuous scale. 11.5 When to Use Ridgeline plots can be used when a number of data segments have to be plotted on the same horizontal scale. It is presented with slight overlap. Ridgeline plots are very useful to visualize the distribution of a categorical variable over time or space. A good example using ridgeline plots will be a great example is visualizing the distribution of salary over different departments in a company. 11.6 Considerations The overlapping of the density plot can be controlled by adjusting the value of scale. Scale defines how much the peak of the lower curve touches the curve above. library(&quot;ggridges&quot;) library(&quot;tidyverse&quot;) OrchardSprays_data &lt;- OrchardSprays ggplot(OrchardSprays_data, aes(x=decrease,y=treatment,fill=treatment))+ geom_density_ridges_gradient(scale=3) + theme_ridges()+ scale_y_discrete(expand = c(0.3, 0)) + scale_x_continuous(expand = c(0.01, 0))+ labs(x=&quot;Response in repelling honeybees&quot;,y=&quot;Treatment&quot;)+ ggtitle(&quot;Density estimation of response by honeybees to a treatment for scale=3&quot;)+ theme(plot.title = element_text(hjust = 0.5)) ggplot(OrchardSprays_data, aes(x=decrease,y=treatment,fill=treatment))+ geom_density_ridges_gradient(scale=5) + theme_ridges()+ scale_y_discrete(expand = c(0.3, 0)) + scale_x_continuous(expand = c(0.01, 0))+ labs(x=&quot;Response in repelling honeybees&quot;,y=&quot;Treatment&quot;)+ ggtitle(&quot;Density estimation of response by honeybees to a treatment for scale=5&quot;)+ theme(plot.title = element_text(hjust = 0.5)) Ridgeline plots can also be used to plot histograms on the common horizontal axis rather than density plots. But doing that may not give us any valuable results. library(&quot;ggridges&quot;) library(&quot;tidyverse&quot;) ggplot(InsectSprays, aes(x = count, y = spray, height = ..density.., fill = spray)) + geom_density_ridges(stat = &quot;binline&quot;, bins = 20, scale = 0.7, draw_baseline = FALSE) If the same thing is done in ridgeline plots, it gives better results. library(&quot;ggridges&quot;) library(&quot;tidyverse&quot;) ggplot(InsectSprays, aes(x=count,y=spray,fill=spray))+ geom_density_ridges_gradient() + theme_ridges()+ labs(x=&quot;Count of Insects&quot;,y=&quot;Types of Spray&quot;)+ ggtitle(&quot;The counts of insects treated with different insecticides.&quot;)+ theme(plot.title = element_text(hjust = 0.5)) 11.7 External Resources Introduction to ggridges: An excellent collection of code examples on how to make ridgeline plots with ggplot2. Covers every parameter of ggridges and how to modify them for better visualization. If you want a ridgeline plot to look a certain way, this article will help. Article on ridgeline plots with ggplot2: Few examples using different examples. Great for starting with ridgeline plots. History of Ridgeline plots: To refer to the theory of ridgeline plots. "],
["scatter.html", "12 Chart: Scatterplot 12.1 Overview 12.2 tl;dr 12.3 Simple examples 12.4 Theory 12.5 When to use 12.6 Considerations 12.7 Modifications 12.8 External resources", " 12 Chart: Scatterplot 12.1 Overview This section covers how to make scatterplots 12.2 tl;dr Fancy Example NOW! Gimme Gimme GIMME! Here’s a look at the relationship between brain weight vs. body weight for 62 species of land mammals: And here’s the code: library(MASS) # data library(ggplot2) # plotting # ratio for color choices ratio &lt;- mammals$brain / (mammals$body*1000) ggplot(mammals, aes(x = body, y = brain)) + # plot points, group by color geom_point(aes(fill = ifelse(ratio &gt;= 0.02, &quot;#0000ff&quot;, ifelse(ratio &gt;= 0.01 &amp; ratio &lt; 0.02, &quot;#00ff00&quot;, ifelse(ratio &gt;= 0.005 &amp; ratio &lt; 0.01, &quot;#00ffff&quot;, ifelse(ratio &gt;= 0.001 &amp; ratio &lt; 0.005, &quot;#ffff00&quot;, &quot;#ffffff&quot;))))), col = &quot;#656565&quot;, alpha = 0.5, size = 4, shape = 21) + # add chosen text annotations geom_text(aes(label = ifelse(row.names(mammals) %in% c(&quot;Mouse&quot;, &quot;Human&quot;, &quot;Asian elephant&quot;, &quot;Chimpanzee&quot;, &quot;Owl monkey&quot;, &quot;Ground squirrel&quot;), paste(as.character(row.names(mammals)), &quot;→&quot;, sep = &quot; &quot;),&#39;&#39;)), hjust = 1.12, vjust = 0.3, col = &quot;grey35&quot;) + geom_text(aes(label = ifelse(row.names(mammals) %in% c(&quot;Golden hamster&quot;, &quot;Kangaroo&quot;, &quot;Water opossum&quot;, &quot;Cow&quot;), paste(&quot;←&quot;, as.character(row.names(mammals)), sep = &quot; &quot;),&#39;&#39;)), hjust = -0.12, vjust = 0.35, col = &quot;grey35&quot;) + # customize legend/color palette scale_fill_manual(name = &quot;Brain Weight, as the\\n% of Body Weight&quot;, values = c(&#39;#d7191c&#39;,&#39;#fdae61&#39;,&#39;#ffffbf&#39;,&#39;#abd9e9&#39;,&#39;#2c7bb6&#39;), breaks = c(&quot;#0000ff&quot;, &quot;#00ff00&quot;, &quot;#00ffff&quot;, &quot;#ffff00&quot;, &quot;#ffffff&quot;), labels = c(&quot;Greater than 2%&quot;, &quot;Between 1%-2%&quot;, &quot;Between 0.5%-1%&quot;, &quot;Between 0.1%-0.5%&quot;, &quot;Less than 0.1%&quot;)) + # formatting scale_x_log10(name = &quot;Body Weight&quot;, breaks = c(0.01, 1, 100, 10000), labels = c(&quot;10 g&quot;, &quot;1 kg&quot;, &quot;100 kg&quot;, &quot;10K kg&quot;)) + scale_y_log10(name = &quot;Brain Weight&quot;, breaks = c(1, 10, 100, 1000), labels = c(&quot;1 g&quot;, &quot;10 g&quot;, &quot;100 g&quot;, &quot;1 kg&quot;)) + ggtitle(&quot;An Elephant Never Forgets...How Big A Brain It Has&quot;, subtitle = &quot;Brain and Body Weights of Sixty-Two Species of Land Mammals&quot;) + labs(caption = &quot;Source: MASS::mammals&quot;) + theme(plot.title = element_text(face = &quot;bold&quot;)) + theme(plot.subtitle = element_text(face = &quot;bold&quot;, color = &quot;grey35&quot;)) + theme(plot.caption = element_text(color = &quot;grey68&quot;)) + theme(legend.position = c(0.832, 0.21)) For more info on this dataset, type ?MASS::mammals into the console. And if you are going crazy not knowing what species is in the top right corner, it’s another elephant. Specifically, it’s the African elephant. It also never forgets how big a brain it has. 12.3 Simple examples That was too fancy! Much simpler please! Let’s use the SpeedSki dataset from GDAdata to look at how the speed achieved by the participants related to their birth year: library(GDAdata) head(SpeedSki, n = 7) ## Rank Bib FIS.Code Name Year Nation Speed Sex Event ## 1 1 61 7039 ORIGONE Simone 1979 ITA 211.67 Male Speed One ## 2 2 59 7078 ORIGONE Ivan 1987 ITA 209.70 Male Speed One ## 3 3 66 190130 MONTES Bastien 1985 FRA 209.69 Male Speed One ## 4 4 57 7178 SCHROTTSHAMMER Klaus 1979 AUT 209.67 Male Speed One ## 5 5 69 510089 MAY Philippe 1970 SUI 209.19 Male Speed One ## 6 6 75 7204 BILLY Louis 1993 FRA 208.33 Male Speed One ## 7 7 67 7053 PERSSON Daniel 1975 SWE 208.03 Male Speed One ## no.of.runs ## 1 4 ## 2 4 ## 3 4 ## 4 4 ## 5 4 ## 6 4 ## 7 4 12.3.1 Scatterplot using base R x &lt;- SpeedSki$Year y &lt;- SpeedSki$Speed # plot data plot(x, y, main = &quot;Scatterplot of Speed vs. Birth Year&quot;) Base R scatterplots are easy to make. All you need are the two variables you want to plot. Although scatterplots can be made with categorical data, the variables you are plotting will usually be continuous. 12.3.2 Scatterplot using ggplot2 library(GDAdata) # data library(ggplot2) # plotting # main plot scatter &lt;- ggplot(SpeedSki, aes(Year, Speed)) + geom_point() # show with trimmings scatter + labs(x = &quot;Birth Year&quot;, y = &quot;Speed Achieved (km/hr)&quot;) + ggtitle(&quot;Ninety-One Skiers by Birth Year and Speed Achieved&quot;) ggplot2 makes it very easy to create scatterplots. Using geom_point(), you can easily plot two different aesthetics in one graph. It also is simple to add on extra formatting to make your plots look nice (All that is really necessary is the data, the aesthetics, and the geom). 12.4 Theory For more info about adding lines/contours, comparing groups, and plotting continuous variables check out Chapter 5 of the textbook. 12.5 When to use Scatterplots are great for exploring relationships between variables. Basically, if you are interested in how variables relate to each other, the scatterplot is a great place to start. 12.6 Considerations 12.6.1 Overlapping data Data with similar values will overlap in a scatterplot and may lead to problems. Consider exploring alpha blending or jittering as remedies (links from Overlapping Data section of Iris Walkthrough). 12.6.2 Scaling Consider how scaling can modify how your data will be perceived: library(ggplot2) num_points &lt;- 100 wide_x &lt;- c(rnorm(n = 50, mean = 100, sd = 2), rnorm(n = 50, mean = 10, sd = 2)) wide_y &lt;- rnorm(n = num_points, mean = 5, sd = 2) df &lt;- data.frame(wide_x, wide_y) ggplot(df, aes(wide_x, wide_y)) + geom_point() + ggtitle(&quot;Linear X-Axis&quot;) ggplot(df, aes(wide_x, wide_y)) + geom_point() + ggtitle(&quot;Log-10 X-Axis&quot;) + scale_x_log10() 12.7 Modifications 12.7.1 Contour lines Contour lines give a sense of the density of the data at a glance. For these contour maps, we will use the SpeedSki dataset. Contour lines can be added to the plot call using geom_density_2d(): ggplot(SpeedSki, aes(Year, Speed)) + geom_density_2d() Contour lines work best when combined with other layers: ggplot(SpeedSki, aes(Year, Speed)) + geom_point() + geom_density_2d(bins = 5) 12.7.2 Scatterplot matrices If you want to compare multiple parameters to each other, consider using a scatterplot matrix. This will allow you to show many comparisons in a compact and efficient manner. For these scatterplot matrices, we will use the movies dataset from the ggplot2movies package. As a default, the base R plot() function will create a scatterplot matrix when given multiple variables: library(ggplot2movies) # data library(dplyr) # manipulation index &lt;- sample(nrow(movies), 500) #sample data moviedf &lt;- movies[index,] # data frame splomvar &lt;- moviedf %&gt;% dplyr::select(length, budget, votes, rating, year) plot(splomvar) While this is quite useful for personal exploration of a datset, it is not recommended for presentation purposes. Something called the Hermann grid illusion makes this plot very difficult to examine. To remove this problem, consider using the splom() function from the lattice package: library(lattice) #sploms splom(splomvar) 12.8 External resources Quick-R article about scatterplots using Base R. Goes from the simple into the very fancy, with Matrices, High Density, and 3D versions. STHDA Base R: article on scatterplots in Base R. More examples of how to enhance the humble graph. STHDA ggplot2: article on scatterplots in ggplot2. Heavy on the formatting options available and facet warps. Stack Overflow on adding labels to points from geom_point() ggplot2 cheatsheet: Always good to have close by. "],
["qqplot.html", "13 Chart: QQ-Plot 13.1 Introduction 13.2 Interpreting qqplots 13.3 Normal or not (examples using qqnorm) 13.4 Different kinds of qqplots 13.5 qqplot using ggplot 13.6 References", " 13 Chart: QQ-Plot This chapter originated as a community contribution created by hao871563506 This page is a work in progress. We appreciate any input you may have. If you would like to help improve this page, consider contributing to our repo. 13.1 Introduction In statistics, a Q-Q (quantile-quantile) plot is a probability plot, which is a graphical method for comparing two probability distributions by plotting their quantiles against each other. A point (x, y) on the plot corresponds to one of the quantiles of the second distribution (y-coordinate) plotted against the same quantile of the first distribution (x-coordinate). Thus the line is a parametric curve with the parameter which is the number of the interval for the quantile. 13.2 Interpreting qqplots 13.3 Normal or not (examples using qqnorm) 13.3.1 Normal qqplot x &lt;- rnorm(1000, 50, 10) qqnorm(x) qqline(x, col = &quot;red&quot;) The points seem to fall along a straight line. Notice the x-axis plots the theoretical quantiles. Those are the quantiles from the standard Normal distribution with mean 0 and standard deviation 1. 13.3.2 Non-normal qqplot x &lt;- rexp(1000, 5) qqnorm(x) qqline(x, col = &quot;red&quot;) Notice the points form a curve instead of a straight line. Normal Q-Q plots that look like this usually mean your sample data are skewed. 13.4 Different kinds of qqplots The following graph is a conclusion of all the kinds of qqplot: via Stack Exchange Normal qqplot: The normal distribution is symmetric, so it has no skew (the mean is equal to the median). Right skewed qqplot: Right-skew is also known as positive skew. Left skewed qqplot: Left-skew is also known as negative skew. Light tailed qqplot: meaning that compared to the normal distribution there is little more data located at the extremes of the distribution and less data in the center of the distribution. Heavy tailed qqplot: meaning that compared to the normal distribution there is much more data located at the extremes of the distribution and less data in the center of the distribution. Biomodel qqplot: illustrate a bimodal distribution. 13.5 qqplot using ggplot In order to use ggplot2 to plot a qqplot, we must use a dataframe, so here we convert it to one. We can see that using ggplot to plot a qqplot has a similar outcome as using qqnorm library(ggplot2) x &lt;- rnorm(1000, 50, 10) x &lt;- data.frame(x) ggplot(x, aes(sample = x)) + stat_qq() + stat_qq_line() However, when we need to plot different groups, ggplot will be very helpful with its coloring by factor. library(ggplot2) ggplot(mtcars, aes(sample = mpg, colour = factor(cyl))) + stat_qq() + stat_qq_line() 13.6 References Understanding Q-Q Plots: A discussion from the University of Virginia Library on qqplots. How to interpret a QQ plot: Another resource for interpreting qqplots. A QQ Plot Dissection Kit: An excellent walkthrough on qqplots by Sean Kross. Probability plotting methods for the analysis of data: Paper on plotting techniques, which discusses qqplots. (Wilk, M.B.; Gnanadesikan, R. (1968)) QQ-Plot Wiki: Wikipedia entry on qqplots "],
["violin.html", "14 Chart: Violin Plot 14.1 Overview 14.2 Some Examples in R 14.3 Adding Statistics to the Violin Plot 14.4 Description 14.5 When to use 14.6 External Resources", " 14 Chart: Violin Plot This chapter originated as a community contribution created by AshwinJay101 This page is a work in progress. We appreciate any input you may have. If you would like to help improve this page, consider contributing to our repo. 14.1 Overview This section covers how to make violin plots. 14.2 Some Examples in R Let’s use the chickwts dataset from the datasets package to plot a violin plot using ggplot2. Here’s the code for that: # import ggplot and the Datasets Package library(datasets) library(ggplot2) supps &lt;- c(&quot;horsebean&quot;, &quot;linseed&quot;, &quot;soybean&quot;, &quot;meatmeal&quot;, &quot;sunflower&quot;, &quot;casein&quot;) # plot data ggplot(chickwts, aes(x = factor(feed, levels = supps), y = weight)) + # plotting geom_violin(fill = &quot;lightBlue&quot;, color = &quot;#473e2c&quot;) + labs(x = &quot;Feed Supplement&quot;, y = &quot;Chick Weight (g)&quot;) 14.3 Adding Statistics to the Violin Plot 14.3.1 Adding the median and the interquartile range We can add the median and the interquartile range to the violin plot ggplot(chickwts, aes(x = factor(feed, levels = supps), y = weight)) + # plotting geom_violin(fill = &quot;lightBlue&quot;, color = &quot;#473e2c&quot;) + labs(x = &quot;Feed Supplement&quot;, y = &quot;Chick Weight (g)&quot;) + geom_boxplot(width=0.1) To get the result, we just add a boxplot geom. 14.3.2 Displaying data as dots ggplot(chickwts, aes(x = factor(feed, levels = supps), y = weight)) + # plotting geom_violin(fill = &quot;lightBlue&quot;, color = &quot;#473e2c&quot;) + labs(x = &quot;Feed Supplement&quot;, y = &quot;Chick Weight (g)&quot;) + geom_dotplot(binaxis=&#39;y&#39;, dotsize=0.5, stackdir=&#39;center&#39;) 14.4 Description Violin plots are similar to box plots. The advantage they have over box plots is that they allow us to visualize the distribution of the data and the probability density. We can think of violin plots as a combination of boxplots and density plots. This plot type allows us to see whether the data is unimodal, bimodal or multimodal. These simple details will be hidden in the boxplot. The distribution can be seen through the width of the violin plot. 14.5 When to use Violin plots should be used to display continuous variables only. 14.6 External Resources ggplot2 Violin Plot: Excellent resource for showing the various customizations that can be added to the violin plot. "],
["dates.html", "15 Dates in R 15.1 Introduction 15.2 Converting to Date class 15.3 Working with Date Class 15.4 Plotting with a Date class variable", " 15 Dates in R 15.1 Introduction Working with dates and time can be very frustrating. In general, work with the least cumbersome class. That means if your variable is years, store it as an integer; there’s no reason to use a date or date-time class. If your variable does not involve time, use the Date class in R. 15.2 Converting to Date class You can convert character data to Date class with as.Date(): dchar &lt;- &quot;2018-10-12&quot; ddate &lt;- as.Date(dchar) Note that the two appear the same, although the class is different: dchar ## [1] &quot;2018-10-12&quot; ddate ## [1] &quot;2018-10-12&quot; class(dchar) ## [1] &quot;character&quot; class(ddate) ## [1] &quot;Date&quot; If the date is not in YYYY-MM-DD or YYYY/MM/DD form, you will need to specify the format to convert to Date class, using conversion specifications that begin with %, such as: as.Date(&quot;Thursday, January 6, 2005&quot;, format = &quot;%A, %B %d, %Y&quot;) ## [1] &quot;2005-01-06&quot; For a list of the conversion specifications available in R, see ?strptime. The tidyverse lubridate makes it easy to convert dates that are not in standard format with ymd(), ydm(), mdy(), myd(), dmy(), and dym() (among many other useful date-time functions): lubridate::mdy(&quot;April 13, 1907&quot;) ## [1] &quot;1907-04-13&quot; Try as.Date(&quot;April 13, 1907&quot;) and you will see the benefit of using a lubridate function. 15.3 Working with Date Class It is well worth the effort to convert to Date class, because there’s a lot you can do with dates in a Date class that you can’t do if you store the dates as character data. Number of days between dates: as.Date(&quot;2017-11-02&quot;) - as.Date(&quot;2017-01-01&quot;) ## Time difference of 305 days Compare dates: as.Date(&quot;2017-11-12&quot;) &gt; as.Date(&quot;2017-3-3&quot;) ## [1] TRUE Note that Sys.Date() returns today’s date as a Date class: Sys.Date() ## [1] &quot;2018-11-06&quot; class(Sys.Date()) ## [1] &quot;Date&quot; R has functions to pull particular pieces of information from a date: today &lt;- Sys.Date() weekdays(today) ## [1] &quot;Tuesday&quot; weekdays(today, abbreviate = TRUE) ## [1] &quot;Tue&quot; months(today) ## [1] &quot;November&quot; months(today, abbreviate = TRUE) ## [1] &quot;Nov&quot; quarters(today) ## [1] &quot;Q4&quot; The lubridate package provides additional functions to extract information from a date: today &lt;- Sys.Date() lubridate::year(today) ## [1] 2018 lubridate::yday(today) ## [1] 310 lubridate::month(today) ## [1] 11 lubridate::month(today, label = TRUE) ## [1] Nov ## 12 Levels: Jan &lt; Feb &lt; Mar &lt; Apr &lt; May &lt; Jun &lt; Jul &lt; Aug &lt; Sep &lt; ... &lt; Dec lubridate::mday(today) ## [1] 6 lubridate::week(today) ## [1] 45 lubridate::wday(today) ## [1] 3 15.4 Plotting with a Date class variable Both base R graphics and ggplot2 “know” how to work with a Date class variable, and label the axes properly: 15.4.1 base R df &lt;- read.csv(&quot;data/mortgage.csv&quot;) df$DATE &lt;- as.Date(df$DATE) plot(df$DATE, df$X5.1.ARM, type = &quot;l&quot;) # on the order of years plot(df$DATE[1:30], df$X5.1.ARM[1:30], type = &quot;l&quot;) # switch to months Note the the change in x-axis labels in the second graph. 15.4.2 ggplot2 # readr library(tidyverse) Note that unlike base Rread.csv(), readr::read_csv() automatically reads DATE in as a Date class since it’s in YYYY-MM-DD format: df &lt;- readr::read_csv(&quot;data/mortgage.csv&quot;) ## Parsed with column specification: ## cols( ## DATE = col_date(format = &quot;&quot;), ## `5/1 ARM` = col_double(), ## `15 YR FIXED` = col_double(), ## `30 YR FIXED` = col_double() ## ) g &lt;- ggplot(df, aes(DATE, `30 YR FIXED`)) + geom_line() + theme_grey(14) g ggplot(df %&gt;% filter(DATE &lt; as.Date(&quot;2006-01-01&quot;)), aes(DATE, `30 YR FIXED`)) + geom_line() + theme_grey(14) Again, when the data is filtered, the x-axis labels switch from years to months. 15.4.2.1 Breaks, limits, labels We can control the x-axis breaks, limits, and labels with scale_x_date(): library(lubridate) g + scale_x_date(limits = c(ymd(&quot;2008-01-01&quot;), ymd(&quot;2008-12-31&quot;))) + ggtitle(&quot;limits = c(ymd(\\&quot;2008-01-01\\&quot;), ymd(\\&quot;2008-12-31\\&quot;))&quot;) g + scale_x_date(date_breaks = &quot;4 years&quot;) + ggtitle(&quot;scale_x_date(date_breaks = \\&quot;4 years\\&quot;)&quot;) g + scale_x_date(date_labels = &quot;%Y-%m&quot;) + ggtitle(&quot;scale_x_date(date_labels = \\&quot;%Y-%m\\&quot;)&quot;) (Yes, even in the tidyverse we cannot completely escape the % conversion specification notation. Remember ?strptime for help.) 15.4.2.2 Annotations We can use geom_vline() with annotate() to mark specific events in a time series: ggplot(df, aes(DATE, `30 YR FIXED`)) + geom_line() + geom_vline(xintercept = ymd(&quot;2008-09-29&quot;), color = &quot;blue&quot;) + annotate(&quot;text&quot;, x = ymd(&quot;2008-09-29&quot;), y = 3.75, label = &quot; Market crash\\n 9/29/08&quot;, color = &quot;blue&quot;, hjust = 0) + scale_x_date(limits = c(ymd(&quot;2008-01-01&quot;), ymd(&quot;2009-12-31&quot;)), date_breaks = &quot;1 year&quot;, date_labels = &quot;%Y&quot;) + theme_grey(16) + ggtitle(&quot;`geom_vline()` with `annotate()`&quot;) "],
["maps.html", "16 Spatial Data 16.1 Choropleth maps 16.2 Square bins 16.3 Longitude / Latitude data 16.4 Resources", " 16 Spatial Data This page is a work in progress. We appreciate any input you may have. If you would like to help improve this page, consider contributing to our repo. 16.1 Choropleth maps Cloropleth maps use color to indicate the value of a variable within a defined region, generally political boundaries. The choroplethr package makes it simple to draw choropleth maps of U.S. states, countries, and census tracts, as well as countries of the world; choroplethrZip provides data for zip code level choropleths; choroplethrAdmin1 draws choropleths for administrative regions of world countries. Note: You must install also install choroplethrMaps for choroplethr to work. In addition, choroplethr requires a number of other dependencies which should be installed automatically, but if they aren’t, you can manually install the missing packages that you are notified about when you call library(choroplethr): maptools, and rgdal, sp. We’ll use the state.x77 dataset for this example: library(tidyverse) library(choroplethr) # data frame must contain &quot;region&quot; and &quot;value&quot; columns df_illiteracy &lt;- state.x77 %&gt;% as.data.frame() %&gt;% rownames_to_column(&quot;state&quot;) %&gt;% transmute(region = tolower(`state`), value = Illiteracy) state_choropleth(df_illiteracy, title = &quot;State Illiteracy Rates, 1977&quot;, legend = &quot;Percent Illiterate&quot;) Note: the choroplethr “free course” that you may come across arrives one lesson at a time by email over an extended period so not the best option unless you have a few weeks to spare. 16.2 Square bins Packages such as statebins create choropleth style maps with equal size regions that roughly represent the location of the region, but not the size or shape. Important: Don’t install statebins from CRAN; use the dev version – it contains many improvements, which are detailed in “Statebins Reimagined”. # devtools::install_github(&quot;hrbrmstr/statebins&quot;) library(statebins) df_illit &lt;- state.x77 %&gt;% as.data.frame() %&gt;% rownames_to_column(&quot;state&quot;) %&gt;% select(state, Illiteracy) # Note: direction = 1 switches the order of the fill scale # so darker shades represent higher illiteracy rates # (The default is -1). statebins(df_illit, value_col=&quot;Illiteracy&quot;, name = &quot;%&quot;, direction = 1) + ggtitle(&quot;State Illiteracy Rates, 1977&quot;) + theme_statebins() 16.3 Longitude / Latitude data Note that the options above work with political boundaries, based on the names of the regions that you provide. If you have longitude / latitude data, ggmap is a good choice. It is straight-forward to plot lon/lat data on a Cartestian coordinate system, with the x-axis representation longitude and the y-axis latitude – just be careful not to mix them up. The ggmap package provides a variety of maps that can serve as the backdrop for the long/lat points. ggmap offers a number of different map sources. Google Maps API was the go-to, but they now require you to enable billing through Google Cloud Platorm. You get $300 in free credit, but if providing a credit card isn’t your thing, you may consider using Stamen Maps instead, with the get_stamenmap() function. Use the development version of the package; instructions and extensive examples are available on the package’s GitHub page. 16.4 Resources “Getting started Stamen maps with ggmap” – A short tutorial on using ggmap with Stamen maps using the Sacramento dataset in the caret package. "],
["missing.html", "17 Missing Data 17.1 Overview 17.2 tl;dr 17.3 What are NAs? 17.4 Types of Missing Data 17.5 Missing Patterns 17.6 Handling Missing values 17.7 External Resources", " 17 Missing Data This chapter originated as a community contribution created by ujjwal95 This page is a work in progress. We appreciate any input you may have. If you would like to help improve this page, consider contributing to our repo. 17.1 Overview This section covers what kinds of missing values are encountered in data and how to handle them. 17.2 tl;dr It’s difficult to handle missing data! If your data has some missing values, which it most likely will, you can either remove such rows, such columns, or impute them. 17.3 What are NAs? Whenever data in some row or column in your data is missing, it comes up as NA. Let’s have a look at some data, shall we? Name Sex Age E_mail Education Income Melissa Female 27 NA NA 1.0e+04 Peter NA NA peter.parker@esu.edu NA 7.5e+03 Aang Male 110 aang@avatars.com NA 1.0e+03 Drake Male NA NA NA 5.0e+04 Bruce NA 45 bruce.wayne@wayne.org NA 1.0e+07 Gwen Female 28 gwen.stacy@esu.edu NA 2.3e+04 Ash Male NA ash.ketchum@pokemon.com NA NA NA NA NA NA NA NA We can see the number of NAs in each column and row: colSums(is.na(data)) ## Name Sex Age E_mail Education Income ## 1 3 4 3 8 2 rowSums(is.na(data)) ## [1] 2 3 1 3 2 1 3 6 We can also see the ratio of the number of NAs in each column and row: colMeans(is.na(data)) ## Name Sex Age E_mail Education Income ## 0.125 0.375 0.500 0.375 1.000 0.250 rowMeans(is.na(data)) ## [1] 0.3333333 0.5000000 0.1666667 0.5000000 0.3333333 0.1666667 0.5000000 ## [8] 1.0000000 17.4 Types of Missing Data Missing Completely at Random (MCAR): These are missing data values which are not related to any missing or non-missing values in other columns in the data. Missing at Random (MAR): These are missing data which are linked to one or more groups in the data. The great thing about MAR is that MAR values can be predicted using other features. For example, it may be observed that people older than 70 generally do not enter their income. Most of the data we encounter is MAR. Missing Not at Random (MNAR): Generally, data which is not MAR is MNAR. A big problem is that there is not a huge distinction between MAR and MNAR. We generally assume MAR, unless otherwise known by an outside source. 17.5 Missing Patterns 17.5.1 Missing Patterns by columns We can see some missing patterns in data by columns, ggplot(tidy_names, aes(x = key, y = fct_rev(Name), fill = missing)) + geom_tile(color = &quot;white&quot;) + ggtitle(&quot;Names dataset with NAs added&quot;) + scale_fill_viridis_d() + theme_bw() And we can also add a scale to check the numerical values available in the dataset and look for any trends: library(scales) # for legend # Select columns having numeric values numeric_col_names &lt;- colnames(select_if(data, is.numeric)) filtered_for_numeric &lt;- tidy_names[tidy_names$key %in% numeric_col_names,] filtered_for_numeric$value &lt;- as.integer(filtered_for_numeric$value) # Use label=comma to remove scientific notation ggplot(data = filtered_for_numeric, aes(x = key, y = fct_rev(Name), fill = value)) + geom_tile(color = &quot;white&quot;) + scale_fill_gradient(low = &quot;grey80&quot;, high = &quot;red&quot;, na.value = &quot;black&quot;, label=comma) + theme_bw() Can you see the problem with the above graph? Notice that the scale is for all the variables, hence it cannot show the variable level differences! To solve this problem, we can standardize the variables: filtered_for_numeric &lt;- filtered_for_numeric %&gt;% group_by(key) %&gt;% mutate(Std = (value-mean(value, na.rm = TRUE))/sd(value, na.rm = TRUE)) %&gt;% ungroup() ggplot(filtered_for_numeric, aes(x = key, y = fct_rev(Name), fill = Std)) + geom_tile(color = &quot;white&quot;) + scale_fill_gradient2(low = &quot;blue&quot;, mid = &quot;white&quot;, high =&quot;yellow&quot;, na.value = &quot;black&quot;) + theme_bw() Now, we can see the missing trends better! Let us sort them by the number missing by each row and column: # convert missing to numeric so it can be summed up filtered_for_numeric &lt;- filtered_for_numeric %&gt;% mutate(missing2 = ifelse(missing == &quot;yes&quot;, 1, 0)) ggplot(filtered_for_numeric, aes(x = fct_reorder(key, -missing2, sum), y = fct_reorder(Name, -missing2, sum), fill = Std)) + geom_tile(color = &quot;white&quot;) + scale_fill_gradient2(low = &quot;blue&quot;, mid = &quot;white&quot;, high =&quot;yellow&quot;, na.value = &quot;black&quot;) + theme_bw() 17.5.2 Missing Patterns by rows We can also see missing patterns in data by rows using the mi package: library(mi) x &lt;- missing_data.frame(data) ## Warning in .guess_type(y, favor_ordered, favor_positive, threshold, ## variable_name): Education : cannot infer variable type when all values are ## NA, guessing &#39;irrelevant&#39; ## NOTE: In the following pairs of variables, the missingness pattern of the second is a subset of the first. ## Please verify whether they are in fact logically distinct variables. ## [,1] [,2] ## [1,] &quot;Age&quot; &quot;Income&quot; ## [2,] &quot;Education&quot; &quot;Income&quot; ## Warning in .local(.Object, ...): Some observations are missing on all included variables. ## Often, this indicates a more complicated model is needed for this missingness mechanism image(x) Did you notice that the Education variable has been skipped? That is because the whole column is missing. Let us try to see some patterns in the missing data: x@patterns ## [1] E_mail Sex, Age ## [3] nothing Age, E_mail ## [5] Sex nothing ## [7] Age, Income Name, Sex, Age, E_mail, Income ## 7 Levels: nothing E_mail Sex Sex, Age Age, E_mail ... Name, Sex, Age, E_mail, Income levels(x@patterns) ## [1] &quot;nothing&quot; &quot;E_mail&quot; ## [3] &quot;Sex&quot; &quot;Sex, Age&quot; ## [5] &quot;Age, E_mail&quot; &quot;Age, Income&quot; ## [7] &quot;Name, Sex, Age, E_mail, Income&quot; summary(x@patterns) ## nothing E_mail ## 2 1 ## Sex Sex, Age ## 1 1 ## Age, E_mail Age, Income ## 1 1 ## Name, Sex, Age, E_mail, Income ## 1 We can visualize missing patterns using the visna (VISualize NA) function in the extracat package: extracat::visna(data) Here, the rows represent a missing pattern and the columns represent the column level missing values. The advantage of this graph is that it shows you only the missing patterns available in the data, not all the possible combinations of data (which will be 2^6 = 64), so that you can focus on the pattern in the data itself. We can sort the graph by most to least common missing pattern (i.e., by row): extracat::visna(data, sort = &quot;r&quot;) Or, by most to least missing values (i.e., by column): extracat::visna(data, sort = &quot;c&quot;) Or, by both row and column sort: extracat::visna(data, sort = &quot;b&quot;) 17.6 Handling Missing values There are multiple methods to deal with missing values. 17.6.1 Deletion of rows containing NAs Often we would delete rows that contain NAs when we are handling Missing Completely at Random data. We can delete the rows having NAs as below: na.omit(data) ## [1] Name Sex Age E_mail Education Income ## &lt;0 rows&gt; (or 0-length row.names) This method is called list-wise deletion. It removes all the rows having NAs. But we can see that the Education column is only NAs, so we can remove that column itself: edu_data &lt;- data[, !(colnames(data) %in% c(&quot;Education&quot;))] na.omit(edu_data) ## Name Sex Age E_mail Income ## 3 Aang Male 110 aang@avatars.com 1000 ## 6 Gwen Female 28 gwen.stacy@esu.edu 23000 Another method is pair-wise deletion, in which only the rows having missing values in the variable of interest are removed. 17.6.2 Imputation Techniques Imputation means to replace missing data with substituted values. These techniques are generally used with MAR data. 17.6.2.1 Mean/Median/Mode Imputation We can replace missing data in continuous variables with their mean/median and missing data in discrete/categorical variables with their mode. Either we can replace all the values in the missing variable directly, for example, if “Income” has a median of 15000, we can replace all the missing values in “Income” with 15000, in a technique known as Generalized Imputation. Or, we can replace all values on a similar case basis. For example, we notice that the income of people with Age &gt; 60 is much less than those with Age &lt; 60, on average, and hence we calculate the median income of each Age group separately, and impute values separately for each group. The problem with these methods is that they disturb the underlying distribution of the data. 17.6.3 Model Imputation There are several model based approaches for imputation of data, and several packages, like mice, Hmisc, and Amelia II, which deal with this. For more info, checkout this blog on DataScience+ about imputing missing data with the R mice package. 17.7 External Resources Missing Data Imputation - A PDF by the Stats Department at Columbia University regarding Missing-data Imputation How to deal with missing data in R - A 2 min read blogpost in missing data handling in R Imputing Missing Data in R; MICE package - A 9 min read on how to use the mice package to impute missing values in R How to Handle Missing Data - A great blogpost on how to handle missing data. "],
["network.html", "18 Networks 18.1 visNetwork (interactive)", " 18 Networks 18.1 visNetwork (interactive) visNetwork is a powerful R implementation of the interactive JavaScript vis.js library; it uses tidyverse piping: VisNetwork Docs. –&gt; The Vignette has clear worked-out examples: https://cran.r-project.org/web/packages/visNetwork/vignettes/Introduction-to-visNetwork.html The visNetwork documentation doesn’t provide the same level of explanation as the original, so it’s worth checking out the vis.js documentation as well: http://visjs.org/index.html In particular, the interactive examples are particularly useful for trying out different options. For example, you can test out physics options with this network configurator. 18.1.1 Minimum working example Create a node data frame with a minimum one of column (must be called id) with node names: # nodes boroughs &lt;- data.frame(id = c(&quot;The Bronx&quot;, &quot;Manhattan&quot;, &quot;Queens&quot;, &quot;Brooklyn&quot;, &quot;Staten Island&quot;)) Create a separate data frame of edges with from and to columns. # edges connections &lt;- data.frame(from = c(&quot;The Bronx&quot;, &quot;The Bronx&quot;, &quot;Queens&quot;, &quot;Queens&quot;, &quot;Manhattan&quot;, &quot;Brooklyn&quot;), to = c(&quot;Manhattan&quot;, &quot;Queens&quot;, &quot;Brooklyn&quot;, &quot;Manhattan&quot;, &quot;Brooklyn&quot;, &quot;Staten Island&quot;)) Draw the network with visNetwork(nodes, edges) library(visNetwork) visNetwork(boroughs, connections) Add labels by adding a label column to nodes: library(dplyr) boroughs &lt;- boroughs %&gt;% mutate(label = id) visNetwork(boroughs, connections) 18.1.2 Performance visNetwork can be very slow. %&gt;% visPhysics(stabilization = FALSE) starts rendering before the stabilization is complete, which does actually speed things up but allows you to see what’s happening, which makes a big difference in user experience. (It’s also fun to watch the network stabilize). Other performance tips are described here. 18.1.3 Helpful configuration tools %&gt;% visConfigure(enabled = TRUE) is a useful tool for configuring options interactively. Upon completion, click “generate options” for the code to reproduce the settings. More here (Note that changing options and then viewing them requires a lot of vertical scrolling in the browser. I’m not sure if anything can be done about this. If you have a solution, let me know!) 18.1.4 Coloring nodes Add a column of actual color names to the nodes data frame: boroughs &lt;- boroughs %&gt;% mutate(is.island = c(FALSE, TRUE, FALSE, FALSE, TRUE)) %&gt;% mutate(color = ifelse(is.island, &quot;blue&quot;, &quot;yellow&quot;)) visNetwork(boroughs, connections) 18.1.5 Directed nodes (arrows) visNetwork(boroughs, connections) %&gt;% visEdges(arrows = &quot;to;from&quot;, color = &quot;green&quot;) 18.1.6 Turn off the physics simulation It’s much faster without the simulation. The nodes are randomly placed and can be moved around without affecting the rest of the network, at least in the case of small networks. visNetwork(boroughs, connections) %&gt;% visEdges(physics = FALSE) 18.1.7 Grey out nodes far from selected (defined by “degree”) (Click a node to see effect.) # defaults to 1 degree visNetwork(boroughs, connections) %&gt;% visOptions(highlightNearest = TRUE) # set degree to 2 visNetwork(boroughs, connections) %&gt;% visOptions(highlightNearest = list(enabled = TRUE, degree = 2)) "],
["general.html", "19 General Resources 19.1 Books 19.2 Cheatsheets 19.3 Articles 19.4 Meetups", " 19 General Resources This is a long list of helpful general resources related to EDAV. If you have come across a good resource you don’t see here, consider adding it with a pull request (see the contribute page for more info). 19.1 Books A lot of these are available for students through Columbia Libraries, in both physical and e-book formats. Graphical Data Analysis with R: This book systematically goes through the different types of data, including categorical variables, continuous variables, and time series. The author shows different examples of plotting techniques using ggplot and promoting the “grammar of graphics” model. Code snippets included and available at the book’s website. R for Data Science: The classic. Everything from data types, programming, modeling, communicating, and those keyboard shortcuts you keep forgetting. To quote the book, “this book will teach you how to do data science with R.” Nuff said. 19.2 Cheatsheets Cheatsheet of cheatsheets: Paul van der Laken has put together a large collection of R resource links, including cheat sheets, style guides, package info, blogs, and other helpful resources. RStudio Cheatsheet Collection: Collection of downloadable cheatsheets from RStudio. Includes ones on R Markdown, Data Transformation (dplyr), and Data Visualization (ggplot2). They also have a R Markdown Reference Guide, which is great for remembering that one chunk option that’s on the tip of your tongue. R Base Graphics Cheatsheet: Oddly enough, despite the length of time it’s been around, it’s hard to find a base graphics cheatsheet. Joyce put this one together to help you out if you’re using base graphics. 19.3 Articles Ten Simple Rules for Better Figures: A helpful article discussing how to make the best figures possible by following ten basic rules such as “Avoid ‘chartjunk’” and “Know Your Audience”. Good to keep these rules in mind. The Simpsons by the Data: Nice example of telling a story with data (histograms, scatterplots, etc.). Also, it’s subject is everybody’s favorite TV family. 19.4 Meetups New York Open Statistical Programming Meetup: Meetups hosted by Jared Lander and Wes McKinney on a variety of topics in statistical programming, but with a focus on the R language. Past speakers have included J.J. Allaire (founder of RStudio) and Hadley Wickham (core tidyverse developer). Other attendees are generally eager to welcome newcomers and all of their talks are available on the Lander Analytics Youtube channel. "],
["percept.html", "20 Perception/Color Resources 20.1 Overview 20.2 Perception 20.3 Color 20.4 Quick tips on using color with ggplot2", " 20 Perception/Color Resources 20.1 Overview This section has resources for learning about graphical perception and how to use colors effectively. 20.2 Perception Here are some links to some key books/articles on perception: Graphical Perception: Theory, Experimentation, and Application to the Development of Graphical Methods: Classic article from William Cleveland and Robert McGill The Elements of Graphing Data: Textbook by William Cleveland Visualizing Data: Textbook by William Cleveland Creating More Effective Graphs: Textbook by Naomi Robbins 20.3 Color Color is very subjective. It is important to choose the right ones so that your work is easy to understand. Color Brewer: Excellent resource for getting effective color palettes for different projects. Its main focus is on cartography, but it is super useful for any project involving color. You can choose between different types of data (sequential, diverging, qualitative), ensure your chosen palette is effective for colorblind users (or print friendly or photocopy safe), and easily export the color palette to different formats (Adobe, GIMP/Inkscape, JS, CSS). The best go-to for effective color palettes. Color Blindness Simulator: Not sure how effective your project will be to a colorblind user? This tool can help. You can upload an image to see how it will look with different color vision handicaps. ColorPick Eyedropper: This Chrome extension allows you to copy hex color values from webpages. Simple and intuitive, it will make creating your awesome color palettes a lot easier. 20.4 Quick tips on using color with ggplot2 One of the most common problems is confusing color and fill. geom_point() and geom_line use color, many of the other geoms use fill. Some use both, such as geom_tile() in which case color is the border color and fill is the fill color. 20.4.1 Continuous data 20.4.1.1 ColorBrewer scale_color_distiller(palette = &quot;PuBu&quot;) or scale_fill_distiller(palette = &quot;PuBu&quot;) (What doesn’t work: scale_color_brewer(palette = &quot;PuBu&quot;)) 20.4.1.2 Viridis scale_color_viridis_c() or scale_fill... (the c stands for continuous) 20.4.1.3 Create your own + scale_color_gradient(low = &quot;white&quot;, high = &quot;red&quot;) or + scale_fill... + scale_color_gradient2(low = &quot;red&quot;, mid = &quot;white&quot;, high = &quot;blue&quot;, midpoint = 50) or + scale_fill... + scale_color_gradientn(colours = c(&quot;red&quot;, &quot;pink&quot;, &quot;lightblue&quot;, &quot;blue&quot;)) or scale_fill... 20.4.2 Discrete data 20.4.2.1 ColorBrewer scale_color_brewer(palette = &quot;PuBu&quot;) or scale_fill... 20.4.2.2 Viridis scale_color_viridis_d() or scale_fill... (the d stands for discrete) 20.4.2.3 Create your own + scale_color_manual(values = c(&quot;red&quot;, &quot;yellow&quot;, &quot;blue&quot;)) or scale_fill... + scale_fill_manual(values = c(&quot;red&quot;, &quot;yellow&quot;, &quot;blue&quot;)) or scale_fill... "],
["publish.html", "21 Publishing Resources 21.1 Overview 21.2 tl;dr 21.3 Bookdown 21.4 Essentials 21.5 Adding a custom domain name 21.6 Make a custom 404 page 21.7 Hooking up Travis 21.8 Other resources", " 21 Publishing Resources 21.1 Overview This section discusses how we built edav.info/ and includes references for building sites and books of your own using R. 21.2 tl;dr Want to get started making a site complete with Travis CI like this one? Zach Bogart has created a bookdown-template you can clone and build off of to create your own site. For instructions, consult the README file. 21.3 Bookdown edav.info/ is built using Bookdown, “a free and open-source R package built on top of R Markdown to make it really easy to write books and long-form articles/reports.” The biggest selling-point for bookdown is that it allows you to make content that is both professional and adaptable. If you want to update a regular book, you need to issue another edition and go through a lot of hassle. With bookdown, you can publish it in different formats (including print, if desired) and be able to change things easily when needed. We chose bookdown for edav.info/ because it allows us to present a lot of content in a compact, searchable manner, while also letting students suggest updates and contribute to its structure. Again, it is professional and adaptable (The default bookdown output is essentially just an online book, but we tried to liven it up by adding a lot of helpful icons, logos, and banners to improve navigation). Below are some helpful references we used in creating edav.info/, which may be helpful if you are interested in creating your own website or online resource with R. 21.4 Essentials How to Start a Bookdown Book: The hardest part about bookdown is getting it up and running. Sean Kross has the best template instructions we found. We started this project by cloning his template repo and building off of it. Excellent descriptions on what all the files do and what is essential to start your project. bookdown: Authoring Books and Technical Documents with R Markdown: This textbook by Yihui Xie, author of the bookdown package, explains everything bookdown is able to accomplish (published using bookdown…because of course it is). An incredible informative reference which we always kept close by. Author’s blurb: A guide to authoring books with R Markdown, including how to generate figures and tables, and insert cross-references, citations, HTML widgets, and Shiny apps in R Markdown. RStudio Bookdown Talk: Yihui Xie (author of the bookdown package) discusses his package and what it can do in a one-hour talk. Good for seeing finished examples. bookdown.org: Site for the bookdown package. Has a bunch of popular books published using bookdown and some info about how to get started using the package. Creating Websites in R: This tutorial, written by Emily Zabor (a Columbia alum), provides a thorough walkthrough for creating websites using different R tools. She discusses how to make different kinds of sites (personal, package, project, blog) as well as GitHub integration and step-by-step instructions for getting setup with templates and hosting. Very detailed and worth perusing if interested in making your own site. 21.5 Adding a custom domain name There are several parts to adding a custom domain name. Buy a domain name and edit DNS settings We used Google domains. In the registrar page, click the DNS icon and add the following to Custom resource records: NAME TYPE TTL DATA @ A 1h 185.199.108.153 www CNAME 1h @ Note that some tutorials list older IP addresses. Check here for the recommended ones. Change settings in your repo In Settings, add your custom domain name in the GitHub Pages section. Add a CNAME file to the gh-pages branch This is a very simple text file named CNAME (all caps). The contents should be one line with the custom domain name. For more detail on steps 2 and 3, see: Emily Zabor’s Tutorial on Custom Domains 21.6 Make a custom 404 page Your site may be lovely, but a default 404 page is always a let down. Not if but when someone types part of your URL incorrectly or a link gets broken, you should make sure there is something to see other than a boring backend page you had no input in designing. This article explains the process, but all you have to do is make a file called 404.html in your root directory and GitHub will use it rather than the default. Because of this, there is really no excuse for not having one. Here’s a look at our 404 page. Hopefully you aren’t seeing it that often. Some considerations: Always include a link back to the site: Throw the user a life-saver. Make it clear that something went wrong: Don’t hide the fact that this page is because of some error. Use absolute paths: The URL that throws the 404 error may be nested within unexpected folders. Make sure if you have any images or links, they work regardless of the file path (use “/images/…” rather than “images/…”, maybe link directly to css/homepage, etc.) Other than that, have fun with it!: There are plenty of examples of people making excellent 404 pages. It should make a frustrating experience just a little bit more bearable. 21.7 Hooking up Travis This tutorial is designed to help you add Travis to your GitHub Pages bookdown web site. It assumes you already have a working web site, with pages stored in a gh-pages branch. We’re not necessarily recommending the gh-pages route; we chose it since we found examples that worked for us using this method. Since the /docs folder is a newer and cleaner approach, it is certainly possible that it provides a better way to organize the repo. That said, there are various tutorials for how to set up the gh-pages branch; it appears that the best way to do so is to create an orphan branch, as explained here. We should note that this makes it all seem very easy to add Travis, which actually was not the case at all for us. I guess everything looks easy in retrospect. If you run into trouble, let us know by filing an issue or submitting a pull request. More info on all the contribution stuff can be found on our contribute page. 21.7.1 Add Travis files to GitHub repo Add these files to your repo: https://github.com/rstudio/bookdown-demo/blob/master/.travis.yml No changes https://github.com/rstudio/bookdown-demo/blob/master/_build.sh Remove the last two lines if you’re only interested in a GitHub Pages book. https://github.com/rstudio/bookdown-demo/blob/master/_deploy.sh The only changes you need to make are to the git config lines. You need to use your GitHub email, but the username can be anything. 21.7.2 Add Travis service Create a Travis account on www.travis-ci.org by clicking on “Sign in with GitHub” on the top right. Click Authorize to allow Travis to have proper access to GitHub. Go back to GitHub and create a personal access token (PAT) if you don’t have one already. You can do so here. Note that you must save your PAT somewhere because you can’t access it once it’s created. Also note that the PAT provides a means to access your GitHub repo through an API, an alternative means to logging in with your username/password (There is an API Token in Travis but this is not the one to use). Return to your Travis profile (travis-ci.org/profile/[GITHUB username]) and click the button next to the appropriate repo to toggle it on. Click on Settings next to the button and add your saved GITHUB_PAT under Environmental Variables: set “Name” to “GITHUB_PAT” and “Value” to the value of the token. If all goes well, you can sit back, relax, and watch Travis do the work for you. via GIPHY 21.8 Other resources blogdown: Creating Websites with R Markdown: Textbook on the blogdownpackage, another option for generating websites with R. Getting Started with GitHub Pages: Short article from GitHub Guides on creating/hosting a website using GitHub Pages. A Beginner’s Guide to Travis CI for R: Fantastic blog post by Julia Silge, includes debugging advice that helped us solve a problem involving installing packages with system requirements. "],
["github.html", "22 GitHub Resources 22.1 Overview 22.2 tl;dr 22.3 On GitHub 22.4 Getting started 22.5 Getting help 22.6 Branching out 22.7 Going deeper", " 22 GitHub Resources 22.1 Overview This section includes links for working with GitHub and advice on how to collaborate in teams on large coding projects. 22.2 tl;dr I don’t wanna just read about GitHub; I wanna learn by doing! We love your enthusiasm. To hit the ground running, checkout GitHub Learning Lab. This application will teach you how to use GitHub with hands-on courses using actual repos. Its the perfect way to understand what using GitHub looks like. Want a little reading as well?: Resources to learn Git is a simple site split into two main sections: Learn by reading and Learn by doing. Take your pick. 22.3 On GitHub In this course, you will be working on a project in teams. Because of this, you probably want to be able to share code and work on different parts of the project simultaneously. This is where Git and GitHub comes in. GitHub is a way to work on projects and keep track of their status easily and efficiently. It is built off of Git, a type of version control software. It is super useful and powerful, but people also find it quite annoying and difficult to understand. So, in an effort to help you, we have collected some resources to learn about GitHub and how you can use it to work on projects. 22.4 Getting started What’s GitHub? Start here. Hello World: GitHub’s take on the “Hello World” program. Great starting point to learn how GitHub works. Github Training &amp; Guides: This YouTube Channel has a lot of info about what GitHub can do. The first line of the opening video is, “Okay. You signed up for GitHub. What do you do now?”. If you are asking that very question, this channel will serve you well. 22.5 Getting help If you’re lost, these might help. GitHub Guides: This is a phenomenal collection of short articles from GitHub to help you learn about the fundamentals around their product. They are so great, we have already listed their Hello World article. Here are some other important ones: Understanding the GitHub Flow: Explains how working with GitHub generally goes. Git Handbook: Explains what version control is. GitHub Help: This is the yellow-pages of GitHub. Ask a question and it will try to push you in the right direction. Get it? 22.6 Branching out GitHub is super social. Learn how to git involved! Open Source Guide: Info on how to contribute to open source projects. Great links to the GitHub skills involved as well as good GitHub etiquette to adopt. Forking Projects: Quick read from GitHub on how to fork a repository so you can contribute to it. Mastering Issues: On what Issues are in GitHub and how they can help get things done. Our Page on Contributing: You can contribute to edav.info/ with your new-found GitHub skills! Checkout our page on how to contribute through pull requests and/or issues. 22.7 Going deeper For the nerds in the room… Git For Ages 4 And Up: There’s a lot going on under the hood. This talk will help explain how it all works…with kids toys! Make pretty git logs: Always remember (A DOG). Also, this alias command is nice to have around: git config --global alias.adog &quot;log --all --decorate --oneline --graph&quot; add and commit with one command: Another (even more) helpful alias command: git config --global alias.add-commit '!git add -A &amp;&amp; git commit' Git Aware Prompt: An excellent add-on to the Terminal that informs you which branch you have checked out. Someone also made an even spiffier version where it will inform you of your git status using helpful emojis. "],
["chapter-index.html", "23 Chapter Index 23.1 Overview 23.2 Index", " 23 Chapter Index 23.1 Overview This page includes links to every chapter in edav.info/ Click on a banner to go to the desired page. If you’re wondering, here’s an explanation of what the banner colors mean. 23.2 Index "]
]
